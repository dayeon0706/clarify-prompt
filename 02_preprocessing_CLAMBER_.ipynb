{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "GhJ08czYccaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/MyDrive/woke-odds/clamber_benchmark.jsonl'"
      ],
      "metadata": {
        "id": "BAqNK-NFcdQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "with open(file_path, 'r', encoding='utf-8') as f:\n",
        "    for line_num, line in enumerate(f, 1):\n",
        "        line = line.strip()\n",
        "        if line:\n",
        "            try:\n",
        "                # ì²« ë²ˆì§¸ íŒŒì‹±: ë°”ê¹¥ìª½ ë”°ì˜´í‘œë¡œ ê°ì‹¸ì§„ ë¬¸ìì—´ì„ íŒŒì‹±\n",
        "                parsed_once = json.loads(line)\n",
        "\n",
        "                # ë‘ ë²ˆì§¸ íŒŒì‹±: ì‹¤ì œ JSON ê°ì²´ë¡œ íŒŒì‹±\n",
        "                if isinstance(parsed_once, str):\n",
        "                    item = json.loads(parsed_once)\n",
        "                else:\n",
        "                    item = parsed_once\n",
        "\n",
        "                data.append(item)\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"Line {line_num} - Error: {e}\")\n",
        "                print(f\"Content preview: {line[:100]}...\")\n",
        "                continue\n",
        "\n",
        "# DataFrameìœ¼ë¡œ ë³€í™˜\n",
        "df = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "-r0dhRj_coBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"ì´ ë°ì´í„° ê°œìˆ˜: {len(df)}\")\n",
        "print(f\"\\nì»¬ëŸ¼ ëª©ë¡:\\n{df.columns.tolist()}\")"
      ],
      "metadata": {
        "id": "jLldrAHTcsm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "display(df.head())"
      ],
      "metadata": {
        "id": "kxk93pchdwBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#context ì»¬ëŸ¼ í™•ì¸\n",
        "print((df['context'].str.len() > 0).sum()) #ì‹¤ì œ ë°ì´í„°ê°€ ìˆëŠ” ê°œìˆ˜\n",
        "print(df['context'].str.strip().eq('').sum()) #ê³µë°±ë§Œ ìˆëŠ” ê°œìˆ˜"
      ],
      "metadata": {
        "id": "HcuqFa5ze7mI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop('context', axis=1)"
      ],
      "metadata": {
        "id": "bdHm_nVkfyAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(columns=['predict_ambiguous', 'predict_is_ambiguous_response', 'predict_clarifying_question'])"
      ],
      "metadata": {
        "id": "x2iGTpaFgaPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(df.head())"
      ],
      "metadata": {
        "id": "36dOVcYkgcws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ëª…í™•í™” í•„ìš” ì§ˆë¬¸(1)ì˜ ê°œìˆ˜\n",
        "print(df['require_clarification'].value_counts())"
      ],
      "metadata": {
        "id": "wJlI8sjVgtky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# category ê°’ ê°œìˆ˜ ì¡°íšŒ\n",
        "print(df['category'].value_counts())\n",
        "print(\"ë¹„ìœ¨(%):\")\n",
        "print(df['category'].value_counts(normalize=True) * 100)\n",
        "print()\n",
        "\n",
        "# subclass ê°’ ê°œìˆ˜ ì¡°íšŒ\n",
        "print(df['subclass'].value_counts())\n",
        "print(\"ë¹„ìœ¨(%):\")\n",
        "print(df['subclass'].value_counts(normalize=True) * 100)\n",
        "print()\n",
        "\n",
        "# categoryì™€ subclass ì¡°í•© í™•ì¸\n",
        "print(df.groupby(['category', 'subclass']).size().sort_values(ascending=False))"
      ],
      "metadata": {
        "id": "iYWF2_6VhHCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ëª…í™•í™” í•„ìš” ì§ˆë¬¸(1)ì˜ ì¹´í…Œê³ ë¦¬ì™€ ì„œë¸Œì¹´í…Œê³ ë¦¬ ì¡°íšŒ\n",
        "clarification_required = df[df['require_clarification'] == 1]\n",
        "\n",
        "print(clarification_required['category'].value_counts())\n",
        "print()\n",
        "print(clarification_required['subclass'].value_counts())\n",
        "print()\n",
        "print(clarification_required.groupby(['category', 'subclass']).size().sort_values(ascending=False))"
      ],
      "metadata": {
        "id": "0YIVt7_ruZK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ëª…í™•í™” í•„ìš” ì—†ëŠ” ì§ˆë¬¸(0)ì˜ ì¹´í…Œê³ ë¦¬ì™€ ì„œë¸Œì¹´í…Œê³ ë¦¬ ì¡°íšŒ\n",
        "clarification_not_required = df[df['require_clarification'] == 0]\n",
        "\n",
        "print(clarification_not_required['category'].value_counts())\n",
        "print()\n",
        "print(clarification_not_required['subclass'].value_counts())\n",
        "print()\n",
        "print(clarification_not_required.groupby(['category', 'subclass']).size().sort_values(ascending=False))"
      ],
      "metadata": {
        "id": "PPKYJ0vYiQ_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ëª¨í˜¸í•˜ì§€ ì•Šì€ ì§ˆë¬¸ì˜ ì˜ˆì‹œ ì¡°íšŒ\n",
        "sample = df[df['require_clarification'] == 0].iloc[0]\n",
        "print(sample)\n",
        "print()\n",
        "print(f\"Question: {sample['question']}\\n\")"
      ],
      "metadata": {
        "id": "kmWnfNAdjHSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_processed = df.copy()\n",
        "\n",
        "# Category ë§¤í•‘ (FD->EM, MC->AO)\n",
        "category_mapping = {\n",
        "    'FD': 'EM',  # Epistemic Misalignment\n",
        "    'MC': 'AO',  # Aleatoric Output\n",
        "    'LA': 'LA'   # Linguistic Ambiguity (ìœ ì§€)\n",
        "}\n",
        "\n",
        "#category ì´ë¦„ ë³€ê²½ -> ì•½ì–´ì™€ ê°’ ì¼ì¹˜\n",
        "df_processed['category'] = df_processed['category'].replace(category_mapping)\n",
        "#ëª¨í˜¸í•˜ì§€ ì•Šì€ ì§ˆë¬¸(0)ì— ëŒ€í•´ ì¹´í…Œê³ ë¦¬ Noneìœ¼ë¡œ ë³€ê²½\n",
        "df_processed.loc[df_processed['require_clarification'] == 0, 'category'] = 'NONE'\n",
        "\n",
        "# Subclass ë§¤í•‘\n",
        "subclass_mapping = {\n",
        "    'whom': 'WHOM',\n",
        "    'what': 'WHAT',\n",
        "    'when': 'WHEN',\n",
        "    'where': 'WHERE',\n",
        "    'NK': 'UNF',\n",
        "    'ICL': 'CONT',\n",
        "    'co-reference': 'SEM',\n",
        "    'polysemy': 'LEX'\n",
        "}\n",
        "\n",
        "#Subclass ì´ë¦„ ë³€ê²½ -> ì•½ì–´ì™€ ê°’ ì¼ì¹˜\n",
        "df_processed['subclass'] = df_processed['subclass'].replace(subclass_mapping)\n",
        "#ëª¨í˜¸í•˜ì§€ ì•Šì€ ì§ˆë¬¸(0)ì— ëŒ€í•´ ì„œë¸Œí´ë˜ìŠ¤ Noneìœ¼ë¡œ ë³€ê²½\n",
        "df_processed.loc[df_processed['require_clarification'] == 0, 'subclass'] = 'NONE'"
      ],
      "metadata": {
        "id": "rJLIODzcjRPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_processed.head(5))"
      ],
      "metadata": {
        "id": "72vpZWGMrDsU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(df_processed[df_processed['require_clarification'] == 0][['question', 'category', 'subclass']].head(10))"
      ],
      "metadata": {
        "id": "4wygcFygrMjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# categoryì™€ subclass ì¡°í•© í™•ì¸\n",
        "print(df_processed.groupby(['category', 'subclass']).size().sort_values(ascending=False))"
      ],
      "metadata": {
        "id": "WVnsOy-NroWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#í˜¹ì‹œ ëª°ë¼ì„œ NONE ê°’ ì²˜ë¦¬ ì•ˆ í•œ ë°ì´í„°ì…‹ ë‚¨ê¹€\n",
        "\n",
        "df_original_kept = df.copy()\n",
        "# category, subclass ë§¤í•‘ë§Œ ì ìš© (NONE ì„¤ì • ì•ˆ í•¨)\n",
        "df_original_kept['category'] = df_original_kept['category'].replace(category_mapping)\n",
        "df_original_kept['subclass'] = df_original_kept['subclass'].replace(subclass_mapping)\n",
        "\n",
        "# categoryì™€ subclass ì¡°í•© í™•ì¸\n",
        "print(df_original_kept.groupby(['category', 'subclass']).size().sort_values(ascending=False))"
      ],
      "metadata": {
        "id": "m6ibVjErt6QB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ë°ì´í„°ì…‹ Parquet í˜•ì‹ìœ¼ë¡œ ì €ì¥\n",
        "df_processed.to_parquet('/content/drive/MyDrive/Colab Notebooks/woke-odds/df_processed.parquet', index=False)"
      ],
      "metadata": {
        "id": "hLza5zA6yzI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####ëª¨ë¸ ì…ë ¥ í˜•ì‹ì— ë§ê²Œ ë°ì´í„°ì…‹ ë³€í™˜"
      ],
      "metadata": {
        "id": "W8LUXTcVySyt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets scikit-learn -q"
      ],
      "metadata": {
        "id": "nwGTVhkOx0dO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from transformers import AutoTokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import Dataset\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "hoPIWtnbz_B8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1e75d6da"
      },
      "source": [
        "# ë°ì´í„°ì…‹ ë¡œë“œ\n",
        "parquet_path = '/content/drive/MyDrive/woke-odds/df_processed.parquet'\n",
        "df_loaded = pd.read_parquet(parquet_path)\n",
        "\n",
        "print(f\"ë¡œë“œëœ ë°ì´í„° ê°œìˆ˜: {len(df_loaded)}\")\n",
        "display(df_loaded.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"microsoft/Phi-4-mini-reasoning\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model_name,\n",
        "    trust_remote_code=True\n",
        ")"
      ],
      "metadata": {
        "id": "tKvyFFSc0FNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"\"\"You are an AI system that determines if the question requires clarification and classifies the ambiguity.\n",
        "\n",
        "Task:\n",
        "1. Determine if the question requires clarification: clear(no clarification needed) or ambiguous(clarification needed)\n",
        "2. Classify the ambiguity:\n",
        "   - If question is clear, set category=NONE and subclass=NONE\n",
        "   - If question is ambiguous, classify category and subclass\n",
        "\n",
        "Output format: category|subclass\n",
        "\n",
        "Categories:\n",
        "- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n",
        "- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n",
        "- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n",
        "- NONE: Clear questions that don't require clarification\n",
        "\n",
        "Subclasses:\n",
        "For EM:\n",
        "- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n",
        "- CONT (CONTRADICTION): Query contains self-contradictions\n",
        "\n",
        "For LA:\n",
        "- LEX (LEXICAL): Query contains terms with multiple meanings\n",
        "- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n",
        "\n",
        "For AO:\n",
        "- WHOM: Query output contains confusion due to missing personal elements\n",
        "- WHEN: Query output contains confusion due to missing temporal elements\n",
        "- WHERE: Query output contains confusion due to missing spatial elements\n",
        "- WHAT: Query output contains confusion due to missing task-specific elements\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "hMQ1lKgfnKo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = []\n",
        "\n",
        "for idx, row in df_loaded.iterrows():\n",
        "    data = {\n",
        "         \"messages\": [\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": system_prompt\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": row['question']\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"assistant\",\n",
        "                \"content\": f\"{row['category']}|{row['subclass']}\"\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "    dataset.append(data)\n",
        "\n",
        "print(f\"ë³€í™˜ ì™„ë£Œ: {len(dataset)}ê°œ\")"
      ],
      "metadata": {
        "id": "nT0L20wxm5lb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ìƒ˜í”Œ í™•ì¸\n",
        "print(json.dumps(dataset[0], indent=2, ensure_ascii=False))"
      ],
      "metadata": {
        "id": "TVaql6Sk4zzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Train/Validation/Test Split"
      ],
      "metadata": {
        "id": "2zf0MzZH9T1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "subclasses = [data['messages'][2]['content'].split('|')[1].strip() for data in dataset]\n",
        "\n",
        "# 1. Train / Temp ë¶„í•  (80:20)\n",
        "train_data, temp_data = train_test_split(\n",
        "    dataset,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=subclasses  # í´ë˜ìŠ¤ ë¹„ìœ¨ ìœ ì§€\n",
        ")\n",
        "\n",
        "temp_subclasses = [data['messages'][2]['content'].split('|')[1].strip() for data in temp_data]\n",
        "\n",
        "# 2. Tempë¥¼ Valid / Test ë¶„í•  (50:50 = ì „ì²´ì˜ 10%:10%)\n",
        "valid_data, test_data = train_test_split(\n",
        "    temp_data,\n",
        "    test_size=0.5,\n",
        "    random_state=42,\n",
        "    stratify=temp_subclasses\n",
        ")\n",
        "\n",
        "print(f\"Train: {len(train_data)}ê°œ (80%)\")\n",
        "print(f\"Valid: {len(valid_data)}ê°œ (10%)\")\n",
        "print(f\"Test: {len(test_data)}ê°œ (10%)\")"
      ],
      "metadata": {
        "id": "ayoWie5AqLJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ì‘ì—… ê²½ë¡œ ì§€ì •\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/woke-odds')\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "id": "zpnyW9Ssq40c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('ambiguity_train_1110.jsonl', 'w', encoding='utf-8') as f:\n",
        "    for data in train_data:\n",
        "        f.write(json.dumps(data, ensure_ascii=False) + '\\n')\n",
        "\n",
        "with open('ambiguity_valid_1110.jsonl', 'w', encoding='utf-8') as f:\n",
        "    for data in valid_data:\n",
        "        f.write(json.dumps(data, ensure_ascii=False) + '\\n')\n",
        "\n",
        "with open('ambiguity_test_1110.jsonl', 'w', encoding='utf-8') as f:\n",
        "    for data in test_data:\n",
        "        f.write(json.dumps(data, ensure_ascii=False) + '\\n')"
      ],
      "metadata": {
        "id": "ZvjsYmFcqNVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[0]"
      ],
      "metadata": {
        "id": "rTxp76gRtL1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####ë°ì´í„°ì…‹ ì €ì¥"
      ],
      "metadata": {
        "id": "etGRQbGj9qYE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#JSONL í˜•ì‹ìœ¼ë¡œ\n",
        "\n",
        "# Train ì €ì¥\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/woke-odds/final_CLAMBER_train.jsonl', 'w', encoding='utf-8') as f:\n",
        "    for item in train_dataset:\n",
        "        f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
        "print(\"âœ… train ì €ì¥ ì™„ë£Œ\")\n",
        "\n",
        "# Validation ì €ì¥\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/woke-odds/final_CLAMBER_valid.jsonl', 'w', encoding='utf-8') as f:\n",
        "    for item in val_dataset:\n",
        "        f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
        "print(\"âœ… valid ì €ì¥ ì™„ë£Œ\")\n",
        "\n",
        "\n",
        "# Test ì €ì¥\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/woke-odds/final_CLAMBER_test.jsonl', 'w', encoding='utf-8') as f:\n",
        "    for item in test_dataset:\n",
        "        f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
        "\n",
        "print(\"âœ… test ì €ì¥ ì™„ë£Œ\")"
      ],
      "metadata": {
        "id": "jbZpOFFD9emT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# JSONL íŒŒì¼ í™•ì¸\n",
        "print(\"ğŸ“„ JSONL íŒŒì¼ ì²« ë²ˆì§¸ ë°ì´í„°:\")\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/woke-odds/final_CLAMBER_train.jsonl', 'r', encoding='utf-8') as f:\n",
        "    first_line = json.loads(f.readline())\n",
        "    print(f\"Question: {first_line['question']}\")\n",
        "    print(f\"Label: {first_line['require_clarification']}|{first_line['category']}|{first_line['subclass']}\")\n",
        "    print(f\"Text preview: {first_line['text'][:200]}...\")\n"
      ],
      "metadata": {
        "id": "zlWlR04J-JFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2SZaJYef-SIP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}