{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install anthropic\n",
        "!pip install tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBF6Kbh_J6pG",
        "outputId": "64cec5d8-0262-40f8-c8d0-e6dcdcc02cf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting anthropic\n",
            "  Downloading anthropic-0.72.1-py3-none-any.whl.metadata (28 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from anthropic) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from anthropic) (1.9.0)\n",
            "Requirement already satisfied: docstring-parser<1,>=0.15 in /usr/local/lib/python3.12/dist-packages (from anthropic) (0.17.0)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from anthropic) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from anthropic) (0.11.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from anthropic) (2.11.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from anthropic) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from anthropic) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->anthropic) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->anthropic) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->anthropic) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.4.2)\n",
            "Downloading anthropic-0.72.1-py3-none-any.whl (357 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m357.4/357.4 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: anthropic\n",
            "Successfully installed anthropic-0.72.1\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "import json\n",
        "import anthropic\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "print(\"라이브러리 임포트 완료!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFif0xq9Ju9S",
        "outputId": "420308ac-d02f-4352-d0be-8832e4251f3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "라이브러리 임포트 완료!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CSV 불러오기\n",
        "csv_path = '/content/drive/MyDrive/Colab Notebooks/woke-odds/dpo_with_candidates_full.csv'\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "print(f\"데이터 로드 완료!\")\n",
        "print(f\"총 데이터 개수: {len(df)}개\")\n",
        "print(f\"컬럼: {df.columns.tolist()}\")\n",
        "\n",
        "# 샘플 확인\n",
        "print(\"\\n첫 번째 샘플:\")\n",
        "display(df.head(1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "S8eq_vppJ4fY",
        "outputId": "dab1fd25-d7d6-4a60-ec09-5753cb88746a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터 로드 완료!\n",
            "총 데이터 개수: 1681개\n",
            "컬럼: ['user_query', 'ground_truth', 'candidate_1', 'candidate_2', 'candidate_3', 'candidate_4', 'candidate_5']\n",
            "\n",
            "첫 번째 샘플:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                          user_query  \\\n",
              "0  [NONE|NONE] Is Pensacola sylvestris a multicel...   \n",
              "\n",
              "               ground_truth               candidate_1         candidate_2  \\\n",
              "0  <NO_CLARIFYING_QUESTION>  <NO_CLARIFYING_QUESTION>  <NO_CQ_QUESTION_1>   \n",
              "\n",
              "                                         candidate_3  \\\n",
              "0  <CLARIFYING_QUESTION| WHOIsanalesicotrophy@yah...   \n",
              "\n",
              "                                         candidate_4  \\\n",
              "0  Do the two entities belong to distinct classes...   \n",
              "\n",
              "                                         candidate_5  \n",
              "0  <NO_CLSF_OR_NUOMCWHX_What_clinical_data_Inform...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-588cd67d-ecdc-4603-a3a5-10e45f22b516\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_query</th>\n",
              "      <th>ground_truth</th>\n",
              "      <th>candidate_1</th>\n",
              "      <th>candidate_2</th>\n",
              "      <th>candidate_3</th>\n",
              "      <th>candidate_4</th>\n",
              "      <th>candidate_5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[NONE|NONE] Is Pensacola sylvestris a multicel...</td>\n",
              "      <td>&lt;NO_CLARIFYING_QUESTION&gt;</td>\n",
              "      <td>&lt;NO_CLARIFYING_QUESTION&gt;</td>\n",
              "      <td>&lt;NO_CQ_QUESTION_1&gt;</td>\n",
              "      <td>&lt;CLARIFYING_QUESTION| WHOIsanalesicotrophy@yah...</td>\n",
              "      <td>Do the two entities belong to distinct classes...</td>\n",
              "      <td>&lt;NO_CLSF_OR_NUOMCWHX_What_clinical_data_Inform...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-588cd67d-ecdc-4603-a3a5-10e45f22b516')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-588cd67d-ecdc-4603-a3a5-10e45f22b516 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-588cd67d-ecdc-4603-a3a5-10e45f22b516');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"user_query\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"[NONE|NONE] Is Pensacola sylvestris a multicellular organism in terms of cellularity?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ground_truth\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"<NO_CLARIFYING_QUESTION>\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"candidate_1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"<NO_CLARIFYING_QUESTION>\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"candidate_2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"<NO_CQ_QUESTION_1>\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"candidate_3\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"<CLARIFYING_QUESTION| WHOIsanalesicotrophy@yahoo.ca] Is it Pensacola's sylvestrias or the subculture \\\"analesecosilviculture?\\\" This entity is unfamiliar to me?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"candidate_4\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Do the two entities belong to distinct classes: sylvestris and/or Pensacola?\\nDo the two entities belong to the genus tree cell-type classification: tree cells?\\nWould you wish to express this in different classes or is this all to be checked as separate classes?\\n\\nDo only entities and tree parts belong, or the cell type classifications which both involve a cell type classification relation in the text string?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"candidate_5\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"<NO_CLSF_OR_NUOMCWHX_What_clinical_data_Information_or_MCOCWHQW> I'm not confident of the information in either entity or text. Could you provide clarification?\\nIf \\\"S1\\\", \\\"F\\\", \\\"A\\\", \\\"G\\\" come to my question, it represents something other what did? What clinical tests include what?\\nPlease provide 14 more facts to clarify my data in terms information?\\nIf it contains multi-instance learning (or multi-instance learning)? I'm confident in any subset for a given text class, with a confidence percentage. Can the confidence be specified?\\nYes or No.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Claude API 키 입력 (실행 시 입력)\n",
        "import getpass\n",
        "\n",
        "api_key = getpass.getpass('Claude API Key를 입력하세요: ')\n",
        "client = anthropic.Anthropic(api_key=api_key)\n",
        "\n",
        "print(\"Claude API 클라이언트 설정 완료!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACJ28RgKKCfX",
        "outputId": "452b11b2-a203-4ce4-f3e3-e8c41dae1c65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Claude API Key를 입력하세요: ··········\n",
            "Claude API 클라이언트 설정 완료!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_candidates_with_rlaif(user_query, ground_truth, candidates):\n",
        "    \"\"\"\n",
        "    Claude API로 후보들을 평가하고 best/rejected 선택\n",
        "\n",
        "    Args:\n",
        "        user_query: 사용자 질문 (카테고리 포함)\n",
        "        ground_truth: 정답 clarifying question\n",
        "        candidates: 생성된 후보 5개 리스트\n",
        "\n",
        "    Returns:\n",
        "        dict: {'best_idx', 'rejected_idx', 'scores', 'reasoning'}\n",
        "    \"\"\"\n",
        "\n",
        "    # 카테고리 추출\n",
        "    category = user_query.split(']')[0] + ']'\n",
        "\n",
        "    # 프롬프트 생성\n",
        "    prompt = f\"\"\"You are an expert rater of clarifying questions for ambiguous queries.\n",
        "\n",
        "AMBIGUITY CATEGORIES GUIDE:\n",
        "\n",
        "- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n",
        "  * UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n",
        "  * CONT (CONTRADICTION): Query contains self-contradictions\n",
        "\n",
        "- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n",
        "  * LEX (LEXICAL): Query contains terms with multiple meanings\n",
        "  * SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n",
        "\n",
        "- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n",
        "  * WHOM: Missing information about WHO (person/agent)\n",
        "  * WHEN: Missing temporal information\n",
        "  * WHERE: Missing spatial/location information\n",
        "  * WHAT: Missing task-specific or object information\n",
        "\n",
        "- NONE: Clear questions that don't require clarification\n",
        "  * Expected response: <NO_CLARIFYING_QUESTION>\n",
        "\n",
        "---\n",
        "\n",
        "EVALUATION TASK:\n",
        "\n",
        "Query: {user_query}\n",
        "Category: {category}\n",
        "\n",
        "Reference Answer (Ground Truth):\n",
        "{ground_truth}\n",
        "\n",
        "Generated Candidates to Evaluate:\n",
        "1. {candidates[0]}\n",
        "2. {candidates[1]}\n",
        "3. {candidates[2]}\n",
        "4. {candidates[3]}\n",
        "5. {candidates[4]}\n",
        "\n",
        "---\n",
        "\n",
        "Your Task:\n",
        "\n",
        "Step 1 - Analyze each candidate:\n",
        "- Does it correctly address the specific ambiguity type indicated in the category?\n",
        "- For example, if category is [AO|WHOM], does it ask about WHO is involved?\n",
        "- Is it clear, specific, and easy to understand?\n",
        "- How does it compare to the reference answer?\n",
        "\n",
        "Step 2 - Assign scores (0-100):\n",
        "- 85-100: Excellent (addresses ambiguity type correctly, comparable to reference)\n",
        "- 70-84: Good (addresses ambiguity but slightly less effective)\n",
        "- 55-69: Acceptable (addresses core issue but noticeably lacking in clarity or specificity)\n",
        "- 40-54: Weak (partially addresses ambiguity or misses key aspects)\n",
        "- 0-39: Poor (doesn't address the right ambiguity type or is ineffective)\n",
        "\n",
        "Step 3 - Select candidates:\n",
        "- BEST: Choose the highest scoring candidate\n",
        "- REJECTED: Choose a candidate in the 60-75 point range\n",
        "  * IMPORTANT: The rejected candidate MUST be different from the best candidate\n",
        "  * If the best candidate is in 60-75 range, choose the SECOND best candidate in that range\n",
        "  * If no other candidate is in 60-75 range, choose the candidate closest to 67 points (excluding the best)\n",
        "  * Avoid candidates above 80 or below 50\n",
        "\n",
        "Provide your response in JSON format ONLY:\n",
        "{{\n",
        "  \"analysis\": \"Brief analysis of all candidates\",\n",
        "  \"scores\": [score1, score2, score3, score4, score5],\n",
        "  \"best_index\": 1-5,\n",
        "  \"rejected_index\": 1-5,\n",
        "  \"rejected_score\": actual_rejected_score,\n",
        "  \"reasoning\": \"Why this rejected candidate has appropriate quality gap\"\n",
        "}}\n",
        "\n",
        "Response:\"\"\"\n",
        "\n",
        "    try:\n",
        "        # Claude API 호출\n",
        "        message = client.messages.create(\n",
        "            model=\"claude-sonnet-4-20250514\",\n",
        "            max_tokens=2000,\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # 응답 파싱\n",
        "        response_text = message.content[0].text\n",
        "\n",
        "        # JSON 추출 (마크다운 코드블록 제거)\n",
        "        response_text = response_text.replace('```json\\n', '').replace('\\n```', '').strip()\n",
        "        if response_text.startswith('```'):\n",
        "            response_text = response_text.split('\\n', 1)[1]\n",
        "        if response_text.endswith('```'):\n",
        "            response_text = response_text.rsplit('\\n', 1)[0]\n",
        "\n",
        "        # JSON 파싱\n",
        "        result = json.loads(response_text)\n",
        "\n",
        "        return result\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"에러 발생: {e}\")\n",
        "        print(f\"응답 텍스트: {response_text[:200] if 'response_text' in locals() else 'N/A'}...\")\n",
        "        return None\n",
        "\n",
        "print(\"✓ RLAIF 평가 함수 정의 완료!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hldu56xdLKW6",
        "outputId": "4c611bf7-d1ec-4c10-f70a-c3b75352f4b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ RLAIF 평가 함수 정의 완료!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_candidates_with_rlaif(user_query, ground_truth, candidates):\n",
        "    \"\"\"\n",
        "    Claude API로 후보들을 평가하고 rejected만 선택\n",
        "\n",
        "    Args:\n",
        "        user_query: 사용자 질문 (카테고리 포함)\n",
        "        ground_truth: 정답 clarifying question (이게 chosen!)\n",
        "        candidates: 생성된 후보 5개 리스트\n",
        "\n",
        "    Returns:\n",
        "        dict: {'rejected_idx', 'rejected_score', 'scores', 'reasoning'}\n",
        "    \"\"\"\n",
        "\n",
        "    # 카테고리 추출\n",
        "    category = user_query.split(']')[0] + ']'\n",
        "\n",
        "    # 프롬프트 생성\n",
        "    prompt = f\"\"\"You are an expert rater of clarifying questions for ambiguous queries.\n",
        "\n",
        "AMBIGUITY CATEGORIES GUIDE:\n",
        "\n",
        "- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n",
        "  * UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n",
        "  * CONT (CONTRADICTION): Query contains self-contradictions\n",
        "\n",
        "- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n",
        "  * LEX (LEXICAL): Query contains terms with multiple meanings\n",
        "  * SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n",
        "\n",
        "- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n",
        "  * WHOM: Missing information about WHO (person/agent)\n",
        "  * WHEN: Missing temporal information\n",
        "  * WHERE: Missing spatial/location information\n",
        "  * WHAT: Missing task-specific or object information\n",
        "\n",
        "- NONE: Clear questions that don't require clarification\n",
        "  * Expected response: <NO_CLARIFYING_QUESTION>\n",
        "\n",
        "---\n",
        "\n",
        "EVALUATION TASK:\n",
        "\n",
        "Query: {user_query}\n",
        "Category: {category}\n",
        "\n",
        "Reference Answer (Ground Truth - this is the CHOSEN response):\n",
        "{ground_truth}\n",
        "\n",
        "Generated Candidates to Evaluate:\n",
        "1. {candidates[0]}\n",
        "2. {candidates[1]}\n",
        "3. {candidates[2]}\n",
        "4. {candidates[3]}\n",
        "5. {candidates[4]}\n",
        "\n",
        "---\n",
        "\n",
        "Your Task:\n",
        "\n",
        "Step 1 - Analyze and score each candidate (0-100):\n",
        "- Does it correctly address the specific ambiguity type indicated in the category?\n",
        "- Is it clear, specific, and easy to understand?\n",
        "- How does it compare to the reference answer?\n",
        "\n",
        "Scoring guide:\n",
        "- 85-100: Excellent (addresses ambiguity type correctly, comparable to reference)\n",
        "- 70-84: Good (addresses ambiguity but slightly less effective)\n",
        "- 55-69: Acceptable (addresses core issue but noticeably lacking in clarity or specificity)\n",
        "- 40-54: Weak (partially addresses ambiguity or misses key aspects)\n",
        "- 0-39: Poor (doesn't address the right ambiguity type or is ineffective)\n",
        "\n",
        "Step 2 - Select the REJECTED candidate:\n",
        "- Choose a candidate in the 60-75 point range\n",
        "- This range is CRITICAL for effective learning in Direct Preference Optimization (DPO)\n",
        "- The rejected candidate should be \"noticeably worse but not terrible\"\n",
        "- If multiple candidates are in 60-75 range, pick the one closest to 67\n",
        "- If NO candidate is in 60-75 range, pick the one closest to this range\n",
        "- Avoid candidates above 80 (too similar to reference) or below 50 (too poor to learn from)\n",
        "\n",
        "Provide your response in JSON format ONLY:\n",
        "{{\n",
        "  \"analysis\": \"Brief analysis of all candidates\",\n",
        "  \"scores\": [score1, score2, score3, score4, score5],\n",
        "  \"rejected_index\": 1-5,\n",
        "  \"rejected_score\": actual_rejected_score,\n",
        "  \"reasoning\": \"Why this rejected candidate has appropriate quality gap for DPO training\"\n",
        "}}\n",
        "\n",
        "Response:\"\"\"\n",
        "\n",
        "    try:\n",
        "        # Claude API 호출\n",
        "        message = client.messages.create(\n",
        "            model=\"claude-sonnet-4-20250514\",\n",
        "            max_tokens=2000,\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # 응답 파싱\n",
        "        response_text = message.content[0].text\n",
        "\n",
        "        # JSON 추출 (마크다운 코드블록 제거)\n",
        "        response_text = response_text.replace('```json\\n', '').replace('\\n```', '').strip()\n",
        "        if response_text.startswith('```'):\n",
        "            response_text = response_text.split('\\n', 1)[1]\n",
        "        if response_text.endswith('```'):\n",
        "            response_text = response_text.rsplit('\\n', 1)[0]\n",
        "\n",
        "        # JSON 파싱\n",
        "        result = json.loads(response_text)\n",
        "\n",
        "        return result\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"에러 발생: {e}\")\n",
        "        print(f\"응답 텍스트: {response_text[:200] if 'response_text' in locals() else 'N/A'}...\")\n",
        "        return None\n",
        "\n",
        "print(\"✓ RLAIF 평가 함수 정의 완료!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Fc2mC7KPmCL",
        "outputId": "ec0d6c29-d647-432b-8100-1a00d9041edb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ RLAIF 평가 함수 정의 완료!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3개 샘플로 출력 테스트"
      ],
      "metadata": {
        "id": "hgbmDiL_SYEo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3개 샘플로 테스트\n",
        "print(\"=\"*80)\n",
        "print(\"3개 샘플로 RLAIF 테스트\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "df_test = df.head(3).copy()\n",
        "\n",
        "for idx in range(len(df_test)):\n",
        "    row = df_test.iloc[idx]\n",
        "\n",
        "    print(f\"\\n[샘플 {idx+1}/3]\")\n",
        "    print(\"-\"*80)\n",
        "    print(f\"User Query: {row['user_query']}\")\n",
        "    print(f\"Ground Truth: {row['ground_truth']}\")\n",
        "\n",
        "    # 후보 리스트\n",
        "    candidates = [\n",
        "        row['candidate_1'],\n",
        "        row['candidate_2'],\n",
        "        row['candidate_3'],\n",
        "        row['candidate_4'],\n",
        "        row['candidate_5']\n",
        "    ]\n",
        "\n",
        "    print(\"\\n후보들:\")\n",
        "    for i, cand in enumerate(candidates, 1):\n",
        "        print(f\"  {i}. {cand}\")\n",
        "\n",
        "    # RLAIF 평가\n",
        "    print(\"\\nClaude 평가 중...\")\n",
        "    result = evaluate_candidates_with_rlaif(\n",
        "        row['user_query'],\n",
        "        row['ground_truth'],\n",
        "        candidates\n",
        "    )\n",
        "\n",
        "    if result:\n",
        "        print(f\"\\n✓ 평가 완료!\")\n",
        "        print(f\"점수: {result['scores']}\")\n",
        "        print(f\"Rejected: 후보 {result['rejected_index']}\")\n",
        "        print(f\"이유: {result['reasoning']}\")\n",
        "    else:\n",
        "        print(\"\\n✗ 평가 실패\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "\n",
        "    # Rate limit 방지\n",
        "    time.sleep(2)\n",
        "\n",
        "print(\"\\n✓ 테스트 완료!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUfXjNMaLUSq",
        "outputId": "a98e5bcf-9047-4065-d30c-5527fc2dd090"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "3개 샘플로 RLAIF 테스트\n",
            "================================================================================\n",
            "\n",
            "\n",
            "[샘플 1/3]\n",
            "--------------------------------------------------------------------------------\n",
            "User Query: [NONE|NONE] Is Pensacola sylvestris a multicellular organism in terms of cellularity?\n",
            "Ground Truth: <NO_CLARIFYING_QUESTION>\n",
            "\n",
            "후보들:\n",
            "  1. <NO_CLARIFYING_QUESTION>\n",
            "  2. <NO_CQ_QUESTION_1>\n",
            "  3. <CLARIFYING_QUESTION| WHOIsanalesicotrophy@yahoo.ca] Is it Pensacola's sylvestrias or the subculture \"analesecosilviculture?\" This entity is unfamiliar to me?\n",
            "  4. Do the two entities belong to distinct classes: sylvestris and/or Pensacola?\n",
            "Do the two entities belong to the genus tree cell-type classification: tree cells?\n",
            "Would you wish to express this in different classes or is this all to be checked as separate classes?\n",
            "\n",
            "Do only entities and tree parts belong, or the cell type classifications which both involve a cell type classification relation in the text string?\n",
            "  5. <NO_CLSF_OR_NUOMCWHX_What_clinical_data_Information_or_MCOCWHQW> I'm not confident of the information in either entity or text. Could you provide clarification?\n",
            "If \"S1\", \"F\", \"A\", \"G\" come to my question, it represents something other what did? What clinical tests include what?\n",
            "Please provide 14 more facts to clarify my data in terms information?\n",
            "If it contains multi-instance learning (or multi-instance learning)? I'm confident in any subset for a given text class, with a confidence percentage. Can the confidence be specified?\n",
            "Yes or No.\n",
            "\n",
            "Claude 평가 중...\n",
            "\n",
            "✓ 평가 완료!\n",
            "점수: [95, 85, 25, 35, 15]\n",
            "Rejected: 후보 2\n",
            "이유: Candidate 2 at 85 points represents a formatting variant of the correct answer that's noticeably inferior to the reference but not fundamentally wrong. This creates an appropriate quality gap for DPO training - it's close enough to be a reasonable attempt but clearly worse than the chosen response due to formatting issues, making it ideal for learning the importance of proper response formatting.\n",
            "\n",
            "================================================================================\n",
            "\n",
            "[샘플 2/3]\n",
            "--------------------------------------------------------------------------------\n",
            "User Query: [AO|WHERE] When did call of duty ww2 come out?\n",
            "Ground Truth: Which one: release, release in the North America, release in Australia, or release in the EU?\n",
            "\n",
            "후보들:\n",
            "  1. Are you asking about a specific game title?\n",
            "  2. Which country does the US have in which war?\n",
            "  3. Which is the source location?\n",
            "  4. Which venue in which country did it take place?\n",
            "  5. Is \"who\" gender-specific?\n",
            "\n",
            "Claude 평가 중...\n",
            "\n",
            "✓ 평가 완료!\n",
            "점수: [45, 15, 35, 20, 10]\n",
            "Rejected: 후보 1\n",
            "이유: Candidate 1 scores 45, making it the closest to the desired 60-75 range for DPO training. It partially addresses the ambiguity by asking for clarification about the specific game, but misses the key spatial/regional aspect that the reference answer correctly identifies. This creates an appropriate quality gap - it's not completely wrong but noticeably inferior to the reference answer's precision in addressing the WHERE ambiguity.\n",
            "\n",
            "================================================================================\n",
            "\n",
            "[샘플 3/3]\n",
            "--------------------------------------------------------------------------------\n",
            "User Query: [EM|UNF] Does Helicotylenchus have Phaseolus galactoides as its host?\n",
            "Ground Truth: What is Helicotylenchus referring to?\n",
            "\n",
            "후보들:\n",
            "  1. Can you provide a list of familiar entities or provide more context regarding the unfamiliar entities in the question?\n",
            "  2. Is the subject in the conversation an organism or a species? Please specify the species name for each.\n",
            "  3. What's the exact location of the mention (Phaseolus galactoides)?\n",
            "  4. Is it an \"entailment\" or \"contradiction\"?\n",
            "  5. Can you re-read, is it a parasite or does host mention in plant species?\n",
            "\n",
            "Claude 평가 중...\n",
            "\n",
            "✓ 평가 완료!\n",
            "점수: [75, 68, 35, 25, 62]\n",
            "Rejected: 후보 2\n",
            "이유: Candidate 2 scores 68, placing it in the ideal 60-75 range for DPO training. It addresses the unfamiliarity issue by asking for species clarification, which is relevant to the ambiguity type, but is less direct and specific than the reference answer. This creates an appropriate quality gap - it's attempting to solve the right problem but in a less effective way, making it perfect for learning the difference between good and better clarifying questions.\n",
            "\n",
            "================================================================================\n",
            "\n",
            "✓ 테스트 완료!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2개 샘플로 df 잘 저장되나 테스트"
      ],
      "metadata": {
        "id": "mgkvBHG7SVM5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2개 샘플만 추출\n",
        "df_test_2 = df.head(2).copy()\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"2개 샘플로 RLAIF 테스트 및 저장 확인\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "# 결과 저장할 컬럼 추가\n",
        "df_test_2['rejected_candidate_idx'] = None\n",
        "df_test_2['rejected_text'] = None  # ← 추가!\n",
        "df_test_2['rejected_score'] = None\n",
        "df_test_2['all_scores'] = None\n",
        "df_test_2['rlaif_reasoning'] = None\n",
        "\n",
        "# 각 샘플 처리\n",
        "for idx in range(len(df_test_2)):\n",
        "    row = df_test_2.iloc[idx]\n",
        "\n",
        "    print(f\"\\n[샘플 {idx+1}/2]\")\n",
        "    print(\"-\"*80)\n",
        "    print(f\"User Query: {row['user_query'][:80]}...\")\n",
        "    print(f\"Ground Truth: {row['ground_truth'][:80]}...\")\n",
        "\n",
        "    # 후보 리스트\n",
        "    candidates = [\n",
        "        row['candidate_1'],\n",
        "        row['candidate_2'],\n",
        "        row['candidate_3'],\n",
        "        row['candidate_4'],\n",
        "        row['candidate_5']\n",
        "    ]\n",
        "\n",
        "    # RLAIF 평가\n",
        "    print(\"Claude 평가 중...\")\n",
        "    result = evaluate_candidates_with_rlaif(\n",
        "        row['user_query'],\n",
        "        row['ground_truth'],\n",
        "        candidates\n",
        "    )\n",
        "\n",
        "    if result:\n",
        "        rejected_idx = result['rejected_index']\n",
        "        rejected_text = candidates[rejected_idx - 1]  # 텍스트 추출\n",
        "\n",
        "        # DataFrame에 저장 (둘 다!)\n",
        "        df_test_2.at[idx, 'rejected_candidate_idx'] = rejected_idx\n",
        "        df_test_2.at[idx, 'rejected_text'] = rejected_text  # ← 텍스트 저장!\n",
        "        df_test_2.at[idx, 'rejected_score'] = result['rejected_score']\n",
        "        df_test_2.at[idx, 'all_scores'] = str(result['scores'])\n",
        "        df_test_2.at[idx, 'rlaif_reasoning'] = result['reasoning']\n",
        "\n",
        "        print(f\"✓ 저장 완료!\")\n",
        "        print(f\"  - Rejected: 후보 {rejected_idx} (점수: {result['rejected_score']})\")\n",
        "    else:\n",
        "        print(\"✗ 평가 실패\")\n",
        "\n",
        "    # Rate limit 방지\n",
        "    time.sleep(2)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"✓ 테스트 완료!\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKDuqb4aLVwj",
        "outputId": "79210d24-f963-451d-f8cb-988e57f7af40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "2개 샘플로 RLAIF 테스트 및 저장 확인\n",
            "================================================================================\n",
            "\n",
            "\n",
            "[샘플 1/2]\n",
            "--------------------------------------------------------------------------------\n",
            "User Query: [NONE|NONE] Is Pensacola sylvestris a multicellular organism in terms of cellula...\n",
            "Ground Truth: <NO_CLARIFYING_QUESTION>...\n",
            "Claude 평가 중...\n",
            "✓ 저장 완료!\n",
            "  - Rejected: 후보 4 (점수: 68)\n",
            "\n",
            "[샘플 2/2]\n",
            "--------------------------------------------------------------------------------\n",
            "User Query: [AO|WHERE] When did call of duty ww2 come out?...\n",
            "Ground Truth: Which one: release, release in the North America, release in Australia, or relea...\n",
            "Claude 평가 중...\n",
            "✓ 저장 완료!\n",
            "  - Rejected: 후보 1 (점수: 65)\n",
            "\n",
            "================================================================================\n",
            "✓ 테스트 완료!\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체 컬럼 확인\n",
        "print(\"저장된 DataFrame 정보:\")\n",
        "print(f\"Shape: {df_test_2.shape}\")\n",
        "print(f\"컬럼: {df_test_2.columns.tolist()}\\n\")\n",
        "\n",
        "# 주요 컬럼만 표시\n",
        "print(\"=\"*80)\n",
        "print(\"저장된 데이터 확인:\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "\n",
        "display(df_test_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "xvuUeaukROkl",
        "outputId": "0287adff-a9a9-458a-9f1c-b40bf574ddc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "저장된 DataFrame 정보:\n",
            "Shape: (2, 12)\n",
            "컬럼: ['user_query', 'ground_truth', 'candidate_1', 'candidate_2', 'candidate_3', 'candidate_4', 'candidate_5', 'rejected_candidate_idx', 'rejected_text', 'rejected_score', 'all_scores', 'rlaif_reasoning']\n",
            "\n",
            "================================================================================\n",
            "저장된 데이터 확인:\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                          user_query  \\\n",
              "0  [NONE|NONE] Is Pensacola sylvestris a multicel...   \n",
              "1     [AO|WHERE] When did call of duty ww2 come out?   \n",
              "\n",
              "                                        ground_truth  \\\n",
              "0                           <NO_CLARIFYING_QUESTION>   \n",
              "1  Which one: release, release in the North Ameri...   \n",
              "\n",
              "                                   candidate_1  \\\n",
              "0                     <NO_CLARIFYING_QUESTION>   \n",
              "1  Are you asking about a specific game title?   \n",
              "\n",
              "                                    candidate_2  \\\n",
              "0                            <NO_CQ_QUESTION_1>   \n",
              "1  Which country does the US have in which war?   \n",
              "\n",
              "                                         candidate_3  \\\n",
              "0  <CLARIFYING_QUESTION| WHOIsanalesicotrophy@yah...   \n",
              "1                      Which is the source location?   \n",
              "\n",
              "                                         candidate_4  \\\n",
              "0  Do the two entities belong to distinct classes...   \n",
              "1    Which venue in which country did it take place?   \n",
              "\n",
              "                                         candidate_5 rejected_candidate_idx  \\\n",
              "0  <NO_CLSF_OR_NUOMCWHX_What_clinical_data_Inform...                      4   \n",
              "1                          Is \"who\" gender-specific?                      1   \n",
              "\n",
              "                                       rejected_text rejected_score  \\\n",
              "0  Do the two entities belong to distinct classes...             68   \n",
              "1        Are you asking about a specific game title?             65   \n",
              "\n",
              "              all_scores                                    rlaif_reasoning  \n",
              "0  [100, 95, 35, 68, 25]  Candidate 4 falls perfectly in the 60-75 range...  \n",
              "1   [65, 15, 20, 18, 12]  Candidate 1 scores 65, placing it in the ideal...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f8debd4b-73b0-41d2-ab94-b4709aa0d537\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_query</th>\n",
              "      <th>ground_truth</th>\n",
              "      <th>candidate_1</th>\n",
              "      <th>candidate_2</th>\n",
              "      <th>candidate_3</th>\n",
              "      <th>candidate_4</th>\n",
              "      <th>candidate_5</th>\n",
              "      <th>rejected_candidate_idx</th>\n",
              "      <th>rejected_text</th>\n",
              "      <th>rejected_score</th>\n",
              "      <th>all_scores</th>\n",
              "      <th>rlaif_reasoning</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[NONE|NONE] Is Pensacola sylvestris a multicel...</td>\n",
              "      <td>&lt;NO_CLARIFYING_QUESTION&gt;</td>\n",
              "      <td>&lt;NO_CLARIFYING_QUESTION&gt;</td>\n",
              "      <td>&lt;NO_CQ_QUESTION_1&gt;</td>\n",
              "      <td>&lt;CLARIFYING_QUESTION| WHOIsanalesicotrophy@yah...</td>\n",
              "      <td>Do the two entities belong to distinct classes...</td>\n",
              "      <td>&lt;NO_CLSF_OR_NUOMCWHX_What_clinical_data_Inform...</td>\n",
              "      <td>4</td>\n",
              "      <td>Do the two entities belong to distinct classes...</td>\n",
              "      <td>68</td>\n",
              "      <td>[100, 95, 35, 68, 25]</td>\n",
              "      <td>Candidate 4 falls perfectly in the 60-75 range...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[AO|WHERE] When did call of duty ww2 come out?</td>\n",
              "      <td>Which one: release, release in the North Ameri...</td>\n",
              "      <td>Are you asking about a specific game title?</td>\n",
              "      <td>Which country does the US have in which war?</td>\n",
              "      <td>Which is the source location?</td>\n",
              "      <td>Which venue in which country did it take place?</td>\n",
              "      <td>Is \"who\" gender-specific?</td>\n",
              "      <td>1</td>\n",
              "      <td>Are you asking about a specific game title?</td>\n",
              "      <td>65</td>\n",
              "      <td>[65, 15, 20, 18, 12]</td>\n",
              "      <td>Candidate 1 scores 65, placing it in the ideal...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f8debd4b-73b0-41d2-ab94-b4709aa0d537')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f8debd4b-73b0-41d2-ab94-b4709aa0d537 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f8debd4b-73b0-41d2-ab94-b4709aa0d537');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-fe2d2652-5ebf-4605-ab4b-9480f4c7cc62\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fe2d2652-5ebf-4605-ab4b-9480f4c7cc62')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-fe2d2652-5ebf-4605-ab4b-9480f4c7cc62 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_ed875724-9422-42f7-8899-1d623b1d25d6\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_test_2')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ed875724-9422-42f7-8899-1d623b1d25d6 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_test_2');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_test_2",
              "summary": "{\n  \"name\": \"df_test_2\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"user_query\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"[AO|WHERE] When did call of duty ww2 come out?\",\n          \"[NONE|NONE] Is Pensacola sylvestris a multicellular organism in terms of cellularity?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ground_truth\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Which one: release, release in the North America, release in Australia, or release in the EU?\",\n          \"<NO_CLARIFYING_QUESTION>\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"candidate_1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Are you asking about a specific game title?\",\n          \"<NO_CLARIFYING_QUESTION>\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"candidate_2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Which country does the US have in which war?\",\n          \"<NO_CQ_QUESTION_1>\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"candidate_3\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Which is the source location?\",\n          \"<CLARIFYING_QUESTION| WHOIsanalesicotrophy@yahoo.ca] Is it Pensacola's sylvestrias or the subculture \\\"analesecosilviculture?\\\" This entity is unfamiliar to me?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"candidate_4\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Which venue in which country did it take place?\",\n          \"Do the two entities belong to distinct classes: sylvestris and/or Pensacola?\\nDo the two entities belong to the genus tree cell-type classification: tree cells?\\nWould you wish to express this in different classes or is this all to be checked as separate classes?\\n\\nDo only entities and tree parts belong, or the cell type classifications which both involve a cell type classification relation in the text string?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"candidate_5\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Is \\\"who\\\" gender-specific?\",\n          \"<NO_CLSF_OR_NUOMCWHX_What_clinical_data_Information_or_MCOCWHQW> I'm not confident of the information in either entity or text. Could you provide clarification?\\nIf \\\"S1\\\", \\\"F\\\", \\\"A\\\", \\\"G\\\" come to my question, it represents something other what did? What clinical tests include what?\\nPlease provide 14 more facts to clarify my data in terms information?\\nIf it contains multi-instance learning (or multi-instance learning)? I'm confident in any subset for a given text class, with a confidence percentage. Can the confidence be specified?\\nYes or No.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rejected_candidate_idx\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 1,\n        \"max\": 4,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rejected_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Are you asking about a specific game title?\",\n          \"Do the two entities belong to distinct classes: sylvestris and/or Pensacola?\\nDo the two entities belong to the genus tree cell-type classification: tree cells?\\nWould you wish to express this in different classes or is this all to be checked as separate classes?\\n\\nDo only entities and tree parts belong, or the cell type classifications which both involve a cell type classification relation in the text string?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rejected_score\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 65,\n        \"max\": 68,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          65,\n          68\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"all_scores\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"[65, 15, 20, 18, 12]\",\n          \"[100, 95, 35, 68, 25]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rlaif_reasoning\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Candidate 1 scores 65, placing it in the ideal 60-75 range for DPO training. It shows some understanding by asking for specificity about the game, but fails to address the key WHERE ambiguity about regional release differences that the reference answer captures. This creates an appropriate quality gap - it's not completely wrong but misses the core spatial ambiguity, making it perfect for learning the distinction between general clarification and targeted spatial disambiguation.\",\n          \"Candidate 4 falls perfectly in the 60-75 range at 68 points. It incorrectly provides clarifying questions for a NONE-category query, but does so in a somewhat coherent manner by asking about entity classification and relationships. This creates an appropriate quality gap for DPO training - it's clearly wrong in approach but not completely incoherent, making it ideal for learning the distinction between queries that need clarification versus those that don't.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 결과 저장할 컬럼 추가\n",
        "df['rejected_candidate_idx'] = None\n",
        "df['rejected_text'] = None\n",
        "df['rejected_score'] = None\n",
        "df['all_scores'] = None\n",
        "df['rlaif_reasoning'] = None\n",
        "\n",
        "print(f\"전체 {len(df)}개 데이터 RLAIF 평가 시작...\")\n",
        "\n",
        "# 배치 처리\n",
        "batch_size = 50\n",
        "total_batches = (len(df) + batch_size - 1) // batch_size\n",
        "\n",
        "for batch_idx in range(total_batches):\n",
        "    start_idx = batch_idx * batch_size\n",
        "    end_idx = min((batch_idx + 1) * batch_size, len(df))\n",
        "\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"[Batch {batch_idx+1}/{total_batches}] Processing {start_idx}-{end_idx}\")\n",
        "    print('='*80)\n",
        "\n",
        "    for idx in tqdm(range(start_idx, end_idx), desc=f\"Batch {batch_idx+1}\"):\n",
        "        row = df.iloc[idx]\n",
        "\n",
        "        # 후보 리스트\n",
        "        candidates = [\n",
        "            row['candidate_1'],\n",
        "            row['candidate_2'],\n",
        "            row['candidate_3'],\n",
        "            row['candidate_4'],\n",
        "            row['candidate_5']\n",
        "        ]\n",
        "\n",
        "        try:\n",
        "            # RLAIF 평가\n",
        "            result = evaluate_candidates_with_rlaif(\n",
        "                row['user_query'],\n",
        "                row['ground_truth'],\n",
        "                candidates\n",
        "            )\n",
        "\n",
        "            if result:\n",
        "                rejected_idx = result['rejected_index']\n",
        "                rejected_text = candidates[rejected_idx - 1]\n",
        "\n",
        "                df.at[idx, 'rejected_candidate_idx'] = rejected_idx\n",
        "                df.at[idx, 'rejected_text'] = rejected_text\n",
        "                df.at[idx, 'rejected_score'] = result['rejected_score']\n",
        "                df.at[idx, 'all_scores'] = str(result['scores'])\n",
        "                df.at[idx, 'rlaif_reasoning'] = result['reasoning']\n",
        "\n",
        "            # Rate limit 방지\n",
        "            time.sleep(1.5)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\n에러 (idx={idx}): {e}\")\n",
        "            time.sleep(5)\n",
        "            continue\n",
        "\n",
        "    # 중간 저장\n",
        "    temp_path = f'/content/drive/MyDrive/Colab Notebooks/woke-odds/rlaif_batch_{batch_idx+1}.csv'\n",
        "    df.iloc[:end_idx].to_csv(temp_path, index=False, encoding='utf-8-sig')\n",
        "    print(f\"\\n✓ 중간 저장: {temp_path}\")\n",
        "\n",
        "print(\"\\n전체 RLAIF 평가 완료!\")\n",
        "\n",
        "# 최종 저장\n",
        "final_path = '/content/drive/MyDrive/Colab Notebooks/woke-odds/rlaif_full_results.csv'\n",
        "df.to_csv(final_path, index=False, encoding='utf-8-sig')\n",
        "print(f\"최종 저장: {final_path}\")"
      ],
      "metadata": {
        "id": "YIfU6If8RWvR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c3513a4-84b6-48fe-f0bc-1258bc672a6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "전체 1681개 데이터 RLAIF 평가 시작...\n",
            "\n",
            "================================================================================\n",
            "[Batch 1/34] Processing 0-50\n",
            "================================================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch 1: 100%|██████████| 50/50 [08:07<00:00,  9.75s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✓ 중간 저장: /content/drive/MyDrive/Colab Notebooks/woke-odds/rlaif_batch_1.csv\n",
            "\n",
            "================================================================================\n",
            "[Batch 2/34] Processing 50-100\n",
            "================================================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch 2: 100%|██████████| 50/50 [08:21<00:00, 10.03s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✓ 중간 저장: /content/drive/MyDrive/Colab Notebooks/woke-odds/rlaif_batch_2.csv\n",
            "\n",
            "================================================================================\n",
            "[Batch 3/34] Processing 100-150\n",
            "================================================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch 3: 100%|██████████| 50/50 [08:05<00:00,  9.71s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✓ 중간 저장: /content/drive/MyDrive/Colab Notebooks/woke-odds/rlaif_batch_3.csv\n",
            "\n",
            "================================================================================\n",
            "[Batch 4/34] Processing 150-200\n",
            "================================================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch 4: 100%|██████████| 50/50 [07:58<00:00,  9.57s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✓ 중간 저장: /content/drive/MyDrive/Colab Notebooks/woke-odds/rlaif_batch_4.csv\n",
            "\n",
            "================================================================================\n",
            "[Batch 5/34] Processing 200-250\n",
            "================================================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch 5: 100%|██████████| 50/50 [07:53<00:00,  9.46s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✓ 중간 저장: /content/drive/MyDrive/Colab Notebooks/woke-odds/rlaif_batch_5.csv\n",
            "\n",
            "================================================================================\n",
            "[Batch 6/34] Processing 250-300\n",
            "================================================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch 6: 100%|██████████| 50/50 [08:11<00:00,  9.84s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✓ 중간 저장: /content/drive/MyDrive/Colab Notebooks/woke-odds/rlaif_batch_6.csv\n",
            "\n",
            "================================================================================\n",
            "[Batch 7/34] Processing 300-350\n",
            "================================================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch 7: 100%|██████████| 50/50 [07:57<00:00,  9.56s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✓ 중간 저장: /content/drive/MyDrive/Colab Notebooks/woke-odds/rlaif_batch_7.csv\n",
            "\n",
            "================================================================================\n",
            "[Batch 8/34] Processing 350-400\n",
            "================================================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch 8: 100%|██████████| 50/50 [07:54<00:00,  9.48s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✓ 중간 저장: /content/drive/MyDrive/Colab Notebooks/woke-odds/rlaif_batch_8.csv\n",
            "\n",
            "================================================================================\n",
            "[Batch 9/34] Processing 400-450\n",
            "================================================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch 9: 100%|██████████| 50/50 [07:58<00:00,  9.58s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✓ 중간 저장: /content/drive/MyDrive/Colab Notebooks/woke-odds/rlaif_batch_9.csv\n",
            "\n",
            "================================================================================\n",
            "[Batch 10/34] Processing 450-500\n",
            "================================================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch 10: 100%|██████████| 50/50 [07:57<00:00,  9.55s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✓ 중간 저장: /content/drive/MyDrive/Colab Notebooks/woke-odds/rlaif_batch_10.csv\n",
            "\n",
            "================================================================================\n",
            "[Batch 11/34] Processing 500-550\n",
            "================================================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch 11: 100%|██████████| 50/50 [08:06<00:00,  9.72s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✓ 중간 저장: /content/drive/MyDrive/Colab Notebooks/woke-odds/rlaif_batch_11.csv\n",
            "\n",
            "================================================================================\n",
            "[Batch 12/34] Processing 550-600\n",
            "================================================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch 12: 100%|██████████| 50/50 [07:56<00:00,  9.53s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✓ 중간 저장: /content/drive/MyDrive/Colab Notebooks/woke-odds/rlaif_batch_12.csv\n",
            "\n",
            "================================================================================\n",
            "[Batch 13/34] Processing 600-650\n",
            "================================================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch 13: 100%|██████████| 50/50 [08:00<00:00,  9.61s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✓ 중간 저장: /content/drive/MyDrive/Colab Notebooks/woke-odds/rlaif_batch_13.csv\n",
            "\n",
            "================================================================================\n",
            "[Batch 14/34] Processing 650-700\n",
            "================================================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch 14: 100%|██████████| 50/50 [07:48<00:00,  9.37s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✓ 중간 저장: /content/drive/MyDrive/Colab Notebooks/woke-odds/rlaif_batch_14.csv\n",
            "\n",
            "================================================================================\n",
            "[Batch 15/34] Processing 700-750\n",
            "================================================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch 15: 100%|██████████| 50/50 [08:06<00:00,  9.72s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✓ 중간 저장: /content/drive/MyDrive/Colab Notebooks/woke-odds/rlaif_batch_15.csv\n",
            "\n",
            "================================================================================\n",
            "[Batch 16/34] Processing 750-800\n",
            "================================================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch 16: 100%|██████████| 50/50 [08:17<00:00,  9.95s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✓ 중간 저장: /content/drive/MyDrive/Colab Notebooks/woke-odds/rlaif_batch_16.csv\n",
            "\n",
            "================================================================================\n",
            "[Batch 17/34] Processing 800-850\n",
            "================================================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch 17: 100%|██████████| 50/50 [08:02<00:00,  9.65s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✓ 중간 저장: /content/drive/MyDrive/Colab Notebooks/woke-odds/rlaif_batch_17.csv\n",
            "\n",
            "================================================================================\n",
            "[Batch 18/34] Processing 850-900\n",
            "================================================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch 18: 100%|██████████| 50/50 [07:54<00:00,  9.50s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✓ 중간 저장: /content/drive/MyDrive/Colab Notebooks/woke-odds/rlaif_batch_18.csv\n",
            "\n",
            "================================================================================\n",
            "[Batch 19/34] Processing 900-950\n",
            "================================================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch 19: 100%|██████████| 50/50 [08:12<00:00,  9.85s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✓ 중간 저장: /content/drive/MyDrive/Colab Notebooks/woke-odds/rlaif_batch_19.csv\n",
            "\n",
            "================================================================================\n",
            "[Batch 20/34] Processing 950-1000\n",
            "================================================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch 20: 100%|██████████| 50/50 [08:11<00:00,  9.83s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✓ 중간 저장: /content/drive/MyDrive/Colab Notebooks/woke-odds/rlaif_batch_20.csv\n",
            "\n",
            "================================================================================\n",
            "[Batch 21/34] Processing 1000-1050\n",
            "================================================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch 21: 100%|██████████| 50/50 [08:00<00:00,  9.61s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✓ 중간 저장: /content/drive/MyDrive/Colab Notebooks/woke-odds/rlaif_batch_21.csv\n",
            "\n",
            "================================================================================\n",
            "[Batch 22/34] Processing 1050-1100\n",
            "================================================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch 22: 100%|██████████| 50/50 [08:02<00:00,  9.65s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✓ 중간 저장: /content/drive/MyDrive/Colab Notebooks/woke-odds/rlaif_batch_22.csv\n",
            "\n",
            "================================================================================\n",
            "[Batch 23/34] Processing 1100-1150\n",
            "================================================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch 23: 100%|██████████| 50/50 [08:25<00:00, 10.11s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✓ 중간 저장: /content/drive/MyDrive/Colab Notebooks/woke-odds/rlaif_batch_23.csv\n",
            "\n",
            "================================================================================\n",
            "[Batch 24/34] Processing 1150-1200\n",
            "================================================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch 24: 100%|██████████| 50/50 [08:30<00:00, 10.21s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✓ 중간 저장: /content/drive/MyDrive/Colab Notebooks/woke-odds/rlaif_batch_24.csv\n",
            "\n",
            "================================================================================\n",
            "[Batch 25/34] Processing 1200-1250\n",
            "================================================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch 25: 100%|██████████| 50/50 [08:26<00:00, 10.14s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✓ 중간 저장: /content/drive/MyDrive/Colab Notebooks/woke-odds/rlaif_batch_25.csv\n",
            "\n",
            "================================================================================\n",
            "[Batch 26/34] Processing 1250-1300\n",
            "================================================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch 26: 100%|██████████| 50/50 [08:20<00:00, 10.01s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✓ 중간 저장: /content/drive/MyDrive/Colab Notebooks/woke-odds/rlaif_batch_26.csv\n",
            "\n",
            "================================================================================\n",
            "[Batch 27/34] Processing 1300-1350\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Batch 27: 100%|██████████| 50/50 [08:21<00:00, 10.02s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ 중간 저장: /content/drive/MyDrive/Colab Notebooks/woke-odds/rlaif_batch_27.csv\n",
            "\n",
            "================================================================================\n",
            "[Batch 28/34] Processing 1350-1400\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Batch 28: 100%|██████████| 50/50 [08:19<00:00,  9.98s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ 중간 저장: /content/drive/MyDrive/Colab Notebooks/woke-odds/rlaif_batch_28.csv\n",
            "\n",
            "================================================================================\n",
            "[Batch 29/34] Processing 1400-1450\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Batch 29: 100%|██████████| 50/50 [08:16<00:00,  9.92s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ 중간 저장: /content/drive/MyDrive/Colab Notebooks/woke-odds/rlaif_batch_29.csv\n",
            "\n",
            "================================================================================\n",
            "[Batch 30/34] Processing 1450-1500\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Batch 30: 100%|██████████| 50/50 [08:02<00:00,  9.65s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ 중간 저장: /content/drive/MyDrive/Colab Notebooks/woke-odds/rlaif_batch_30.csv\n",
            "\n",
            "================================================================================\n",
            "[Batch 31/34] Processing 1500-1550\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Batch 31: 100%|██████████| 50/50 [08:15<00:00,  9.92s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ 중간 저장: /content/drive/MyDrive/Colab Notebooks/woke-odds/rlaif_batch_31.csv\n",
            "\n",
            "================================================================================\n",
            "[Batch 32/34] Processing 1550-1600\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Batch 32: 100%|██████████| 50/50 [08:09<00:00,  9.80s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ 중간 저장: /content/drive/MyDrive/Colab Notebooks/woke-odds/rlaif_batch_32.csv\n",
            "\n",
            "================================================================================\n",
            "[Batch 33/34] Processing 1600-1650\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Batch 33: 100%|██████████| 50/50 [08:19<00:00,  9.99s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ 중간 저장: /content/drive/MyDrive/Colab Notebooks/woke-odds/rlaif_batch_33.csv\n",
            "\n",
            "================================================================================\n",
            "[Batch 34/34] Processing 1650-1681\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Batch 34: 100%|██████████| 31/31 [05:01<00:00,  9.71s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ 중간 저장: /content/drive/MyDrive/Colab Notebooks/woke-odds/rlaif_batch_34.csv\n",
            "\n",
            "전체 RLAIF 평가 완료!\n",
            "최종 저장: /content/drive/MyDrive/Colab Notebooks/woke-odds/rlaif_full_results.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DPO 포맷으로 변환\n",
        "dpo_dataset = []\n",
        "\n",
        "for idx, row in df.iterrows():\n",
        "    dpo_dataset.append({\n",
        "        'prompt': row['user_query'],\n",
        "        'chosen': row['ground_truth'],\n",
        "        'rejected': row['rejected_text']\n",
        "    })\n",
        "\n",
        "df_dpo = pd.DataFrame(dpo_dataset)\n",
        "\n",
        "# 저장\n",
        "dpo_path = '/content/drive/MyDrive/Colab Notebooks/woke-odds/dpo_final_dataset.jsonl'\n",
        "with open(dpo_path, 'w', encoding='utf-8') as f:\n",
        "    for idx, row in df_dpo.iterrows():\n",
        "        f.write(json.dumps(row.to_dict(), ensure_ascii=False) + '\\n')\n",
        "\n",
        "print(f\"✓ DPO 데이터셋 저장 완료: {dpo_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBFJIKdMRKoc",
        "outputId": "17183fd2-f940-4b3a-8686-ead717b2c344"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ DPO 데이터셋 저장 완료: /content/drive/MyDrive/Colab Notebooks/woke-odds/dpo_final_dataset.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_4R12TEBRen_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}