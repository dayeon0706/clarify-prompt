{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOGB7xjJnfYFbHpo/unNpxf"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 출력 테스트"
      ],
      "metadata": {
        "id": "_1IPYyVWorQr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFU7A12tcP50"
      },
      "outputs": [],
      "source": [
        "# Google Drive 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 라이브러리 설치\n",
        "!pip install -q transformers torch accelerate"
      ],
      "metadata": {
        "id": "pdT90WjHerzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "print(\"라이브러리 임포트 완료!\")\n",
        "print(f\"CUDA 사용 가능: {torch.cuda.is_available()}\")"
      ],
      "metadata": {
        "id": "sra_hKZ4e2Q7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 경로 설정\n",
        "model_path = \"/content/drive/MyDrive/Colab Notebooks/woke-odds/checkpoint-best\"\n",
        "\n",
        "# 토크나이저 로드\n",
        "print(\"토크나이저 로딩 중...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "# 특수 토큰 설정\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "print(f\"✓ 토크나이저 로드 완료!\")\n",
        "\n",
        "# 모델 로드\n",
        "print(\"\\n모델 로딩 중...\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_path,\n",
        "    torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32,\n",
        "    device_map=\"auto\" if torch.cuda.is_available() else None\n",
        ")\n",
        "\n",
        "# 평가 모드로 설정\n",
        "model.eval()\n",
        "\n",
        "print(f\"✓ 모델 로드 완료!\")\n",
        "print(f\"Device: {model.device}\")"
      ],
      "metadata": {
        "id": "dPq569dBe3jd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 시스템 프롬프트 (데이터셋 원본)\n",
        "SYSTEM_PROMPT = \"\"\"You are an AI that generates a single, concise clarifying question when a user's query is ambiguous.\n",
        "\n",
        "Task:\n",
        "Generate exactly one clarifying question based on the ambiguity type.\n",
        "If the query is clear and needs no clarification, output: <NO_CLARIFYING_QUESTION>\n",
        "\n",
        "Output format: One clarifying question (or <NO_CLARIFYING_QUESTION> if not needed)\n",
        "\n",
        "Categories:\n",
        "- EM (Epistemic Misalignment): Questions with unfamiliar entities or self-contradictions\n",
        "- LA (Linguistic Ambiguity): Questions with lexical or semantic ambiguity\n",
        "- AO (Aleatoric Output): Questions with missing contextual information causing confusion\n",
        "- NONE: Clear questions that don't require clarification\n",
        "\n",
        "Subclasses:\n",
        "For EM:\n",
        "- UNF (UNFAMILIAR): Query contains unfamiliar entities or facts\n",
        "- CONT (CONTRADICTION): Query contains self-contradictions\n",
        "\n",
        "For LA:\n",
        "- LEX (LEXICAL): Query contains terms with multiple meanings\n",
        "- SEM (SEMANTIC): Query lacks context leading to multiple interpretations\n",
        "\n",
        "For AO:\n",
        "- WHOM: Query output contains confusion due to missing personal elements\n",
        "- WHEN: Query output contains confusion due to missing temporal elements\n",
        "- WHERE: Query output contains confusion due to missing spatial elements\n",
        "- WHAT: Query output contains confusion due to missing task-specific elements\n",
        "\n",
        "For Clear Questions:\n",
        "- NONE: Use when require_clarification=0, output <NO_CLARIFYING_QUESTION>\"\"\"\n",
        "\n",
        "print(\"시스템 프롬프트 정의 완료!\")"
      ],
      "metadata": {
        "id": "1z-h2inNe9K9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 샘플 3개 (messages 형식으로)\n",
        "test_samples = [\n",
        "    {\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "            {\"role\": \"user\", \"content\": \"[LA|LEX] What is the most common type of type used in printing?\"}\n",
        "        ],\n",
        "        \"ground_truth\": \"Are you referring to the most common type of printed characters used in printing, or the most common type of person involved in the printing industry?\"\n",
        "    },\n",
        "    {\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "            {\"role\": \"user\", \"content\": \"[AO|WHEN] Number of oil refineries in the united states?\"}\n",
        "        ],\n",
        "        \"ground_truth\": \"Which one: 2019, or January 2015?\"\n",
        "    },\n",
        "    {\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "            {\"role\": \"user\", \"content\": \"[NONE|NONE] What are the names of the actors who acted in the movie Padayappa?\"}\n",
        "        ],\n",
        "        \"ground_truth\": \"<NO_CLARIFYING_QUESTION>\"\n",
        "    }\n",
        "]\n",
        "\n",
        "print(f\"테스트 샘플 {len(test_samples)}개 준비 완료!\")"
      ],
      "metadata": {
        "id": "NN5s-Vg1fvmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== 모델 출력 테스트 (3개 샘플) ===\\n\")\n",
        "\n",
        "for idx, sample in enumerate(test_samples):\n",
        "    messages = sample['messages']\n",
        "    ground_truth = sample['ground_truth']\n",
        "\n",
        "    # system + user 메시지만 사용 (친구 방식)\n",
        "    input_messages = [msg for msg in messages if msg['role'] != 'assistant']\n",
        "\n",
        "    # user query 추출 (출력용)\n",
        "    user_query = [msg['content'] for msg in messages if msg['role'] == 'user'][0]\n",
        "\n",
        "    # Chat template 적용\n",
        "    prompt = tokenizer.apply_chat_template(\n",
        "        input_messages,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True\n",
        "    )\n",
        "\n",
        "    # 토크나이즈\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    # 생성\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=150,\n",
        "            temperature=0.7,\n",
        "            top_p=0.9,\n",
        "            do_sample=True,\n",
        "            pad_token_id=tokenizer.pad_token_id,\n",
        "            eos_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    # 디코딩 (입력 부분 제외)\n",
        "    generated_text = tokenizer.decode(\n",
        "        outputs[0][inputs['input_ids'].shape[1]:],\n",
        "        skip_special_tokens=True\n",
        "    )\n",
        "\n",
        "    # 출력\n",
        "    print(f\"[샘플 {idx+1}]\")\n",
        "    print(f\"User Query: {user_query}\")\n",
        "    print(f\"\\nGround Truth: {ground_truth}\")\n",
        "    print(f\"\\nModel Output: {generated_text.strip()}\")\n",
        "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "\n",
        "print(\"테스트 완료!\")"
      ],
      "metadata": {
        "id": "6XMf-JDzfzWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Temperature 달리해서 응답 5개씩 생성해보기"
      ],
      "metadata": {
        "id": "8PZX34_tox2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_multiple_candidates(messages, model, tokenizer, num_candidates=5, temperatures=[0.7, 0.9, 1.1, 1.3, 1.5]):\n",
        "    \"\"\"\n",
        "    같은 입력에 대해 다양한 temperature로 여러 후보 응답 생성\n",
        "\n",
        "    Args:\n",
        "        messages: 입력 메시지 리스트\n",
        "        model: 학습된 모델\n",
        "        tokenizer: 토크나이저\n",
        "        num_candidates: 생성할 후보 개수 (기본 5개)\n",
        "        temperatures: 사용할 temperature 리스트\n",
        "\n",
        "    Returns:\n",
        "        candidates: 생성된 후보 응답 리스트\n",
        "    \"\"\"\n",
        "    candidates = []\n",
        "\n",
        "    # system + user 메시지만 사용\n",
        "    input_messages = [msg for msg in messages if msg['role'] != 'assistant']\n",
        "\n",
        "    # Chat template 적용\n",
        "    prompt = tokenizer.apply_chat_template(\n",
        "        input_messages,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True\n",
        "    )\n",
        "\n",
        "    # 토크나이즈\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    print(f\"다양한 temperature로 {num_candidates}개 후보 생성 중...\")\n",
        "\n",
        "    # 각 temperature로 생성\n",
        "    for i, temp in enumerate(temperatures[:num_candidates]):\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=150,\n",
        "                temperature=temp,\n",
        "                top_p=0.95,  # 다양성을 위해 top_p도 높게\n",
        "                do_sample=True,\n",
        "                pad_token_id=tokenizer.pad_token_id,\n",
        "                eos_token_id=tokenizer.eos_token_id\n",
        "            )\n",
        "\n",
        "        # 디코딩\n",
        "        generated_text = tokenizer.decode(\n",
        "            outputs[0][inputs['input_ids'].shape[1]:],\n",
        "            skip_special_tokens=True\n",
        "        ).strip()\n",
        "\n",
        "        candidates.append({\n",
        "            'text': generated_text,\n",
        "            'temperature': temp\n",
        "        })\n",
        "\n",
        "        print(f\"  [{i+1}/{num_candidates}] T={temp:.1f}: {generated_text[:80]}...\")\n",
        "\n",
        "    # 중복 제거\n",
        "    unique_candidates = []\n",
        "    seen_texts = set()\n",
        "    for cand in candidates:\n",
        "        if cand['text'] not in seen_texts:\n",
        "            unique_candidates.append(cand)\n",
        "            seen_texts.add(cand['text'])\n",
        "\n",
        "    print(f\"✓ 총 {len(unique_candidates)}개 고유 후보 생성 완료 (중복 {len(candidates) - len(unique_candidates)}개 제거)\\n\")\n",
        "\n",
        "    return unique_candidates\n",
        "\n",
        "print(\"후보 생성 함수 정의 완료!\")"
      ],
      "metadata": {
        "id": "UlUEjr7GkbE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 샘플 1개에 대해 테스트\n",
        "print(\"=\"*80)\n",
        "print(\"[샘플 1] 후보 생성 테스트\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "sample = test_samples[0]\n",
        "messages = sample['messages']\n",
        "user_query = [msg['content'] for msg in messages if msg['role'] == 'user'][0]\n",
        "ground_truth = sample['ground_truth']\n",
        "\n",
        "print(f\"User Query: {user_query}\\n\")\n",
        "print(f\"Ground Truth: {ground_truth}\\n\")\n",
        "print(\"-\"*80 + \"\\n\")\n",
        "\n",
        "# 5개 후보 생성 (temperature: 0.7, 0.9, 1.1, 1.3, 1.5)\n",
        "candidates_sample1 = generate_multiple_candidates(\n",
        "    messages=messages,\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    num_candidates=5\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"생성된 후보 목록:\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "for idx, cand in enumerate(candidates_sample1, 1):\n",
        "    print(f\"[후보 {idx}] (T={cand['temperature']:.1f})\")\n",
        "    print(f\"{cand['text']}\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "NPy_k77VkcpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모든 샘플에 대해 후보 생성\n",
        "all_candidates = []\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"3개 샘플 전체에 대한 후보 생성 시작\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "for idx, sample in enumerate(test_samples, 1):\n",
        "    messages = sample['messages']\n",
        "    user_query = [msg['content'] for msg in messages if msg['role'] == 'user'][0]\n",
        "\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"[샘플 {idx}] {user_query}\")\n",
        "    print('='*80 + \"\\n\")\n",
        "\n",
        "    # 후보 생성\n",
        "    candidates = generate_multiple_candidates(\n",
        "        messages=messages,\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        num_candidates=5  # 샘플당 5개 후보\n",
        "    )\n",
        "\n",
        "    # 저장\n",
        "    all_candidates.append({\n",
        "        'sample_idx': idx,\n",
        "        'user_query': user_query,\n",
        "        'ground_truth': sample['ground_truth'],\n",
        "        'category': user_query.split(']')[0] + ']',  # 카테고리 추출\n",
        "        'candidates': candidates\n",
        "    })\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(f\"✓ 전체 후보 생성 완료! (총 {len(all_candidates)}개 샘플)\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "id": "8qrlX7Tskflc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 생성된 모든 후보 출력\n",
        "for sample_data in all_candidates:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\"[샘플 {sample_data['sample_idx']}]\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"Query: {sample_data['user_query']}\")\n",
        "    print(f\"Category: {sample_data['category']}\")\n",
        "    print(f\"Ground Truth: {sample_data['ground_truth']}\")\n",
        "    print(f\"\\n생성된 후보 {len(sample_data['candidates'])}개:\")\n",
        "    print(\"-\"*80)\n",
        "\n",
        "    for idx, cand in enumerate(sample_data['candidates'], 1):\n",
        "        print(f\"\\n[후보 {idx}] (Temperature={cand['temperature']:.1f})\")\n",
        "        print(f\"{cand['text']}\")\n",
        "\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "zzT6Bl8ykkKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터셋 불러오기"
      ],
      "metadata": {
        "id": "uX9dXn29rolK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "0CuPDo2Ckovw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/MyDrive/Colab Notebooks/woke-odds/clamber_benchmark.jsonl'"
      ],
      "metadata": {
        "id": "sL9jMqAMrsPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "with open(file_path, 'r', encoding='utf-8') as f:\n",
        "    for line_num, line in enumerate(f, 1):\n",
        "        line = line.strip()\n",
        "        if line:\n",
        "            try:\n",
        "                # 첫 번째 파싱: 바깥쪽 따옴표로 감싸진 문자열을 파싱\n",
        "                parsed_once = json.loads(line)\n",
        "\n",
        "                # 두 번째 파싱: 실제 JSON 객체로 파싱\n",
        "                if isinstance(parsed_once, str):\n",
        "                    item = json.loads(parsed_once)\n",
        "                else:\n",
        "                    item = parsed_once\n",
        "\n",
        "                data.append(item)\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"Line {line_num} - Error: {e}\")\n",
        "                print(f\"Content preview: {line[:100]}...\")\n",
        "                continue\n",
        "\n",
        "# DataFrame으로 변환\n",
        "df = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "PDKzX1NqrvC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"총 데이터 개수: {len(df)}\")\n",
        "print(f\"\\n컬럼 목록:\\n{df.columns.tolist()}\")"
      ],
      "metadata": {
        "id": "QbzGtCp4rz45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "display(df.head())"
      ],
      "metadata": {
        "id": "ol0RxmnKsBKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 컬럼만 선택\n",
        "df_cleaned = df[['question', 'clarifying_question', 'require_clarification', 'category', 'subclass']].copy()\n",
        "\n",
        "print(f\"✓ 컬럼 선택 완료!\")\n",
        "print(f\"총 데이터 개수: {len(df_cleaned)}\")\n",
        "print(f\"컬럼 목록: {df_cleaned.columns.tolist()}\")\n",
        "\n",
        "print(\"\\n결측치 확인:\")\n",
        "print(df_cleaned.isnull().sum())\n",
        "\n",
        "print(\"\\n첫 5개 샘플:\")\n",
        "print(display(df_cleaned.head()))"
      ],
      "metadata": {
        "id": "qhnc_gqOsDTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 컬럼만 선택\n",
        "df_cleaned = df[['question', 'clarifying_question', 'require_clarification', 'category', 'subclass']].copy()\n",
        "\n",
        "# Category 매핑 (FD->EM, MC->AO)\n",
        "category_mapping = {\n",
        "    'FD': 'EM',  # Epistemic Misalignment\n",
        "    'MC': 'AO',  # Aleatoric Output\n",
        "    'LA': 'LA'   # Linguistic Ambiguity (유지)\n",
        "}\n",
        "\n",
        "# Category 이름 변경\n",
        "df_cleaned['category'] = df_cleaned['category'].replace(category_mapping)\n",
        "\n",
        "# 모호하지 않은 질문(0)에 대해 카테고리 NONE으로 변경\n",
        "df_cleaned.loc[df_cleaned['require_clarification'] == 0, 'category'] = 'NONE'\n",
        "\n",
        "# Subclass 매핑\n",
        "subclass_mapping = {\n",
        "    'whom': 'WHOM',\n",
        "    'what': 'WHAT',\n",
        "    'when': 'WHEN',\n",
        "    'where': 'WHERE',\n",
        "    'NK': 'UNF',\n",
        "    'ICL': 'CONT',\n",
        "    'co-reference': 'SEM',\n",
        "    'polysemy': 'LEX'\n",
        "}\n",
        "\n",
        "# Subclass 이름 변경\n",
        "df_cleaned['subclass'] = df_cleaned['subclass'].replace(subclass_mapping)\n",
        "\n",
        "# 모호하지 않은 질문(0)에 대해 서브클래스 NONE으로 변경\n",
        "df_cleaned.loc[df_cleaned['require_clarification'] == 0, 'subclass'] = 'NONE'\n",
        "\n",
        "print(f\"✓ 매핑 완료!\")\n",
        "print(f\"총 데이터 개수: {len(df_cleaned)}\")\n",
        "\n",
        "print(\"\\n변경 후 카테고리 분포:\")\n",
        "print(df_cleaned['category'].value_counts())\n",
        "\n",
        "print(\"\\n변경 후 서브클래스 분포:\")\n",
        "print(df_cleaned['subclass'].value_counts())\n",
        "\n",
        "print(\"\\n첫 5개 샘플:\")\n",
        "display(df_cleaned.head())  # display만 단독으로 사용\n",
        "\n",
        "print(\"\\nrequire_clarification=0인 샘플 확인:\")\n",
        "display(df_cleaned[df_cleaned['require_clarification'] == 0].head())"
      ],
      "metadata": {
        "id": "aeyu05XmxHFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# user_query 생성: [category|subclass] question\n",
        "df_cleaned['user_query'] = df_cleaned.apply(\n",
        "    lambda row: f\"[{row['category']}|{row['subclass']}] {row['question']}\",\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# ground_truth는 clarifying_question으로\n",
        "df_cleaned['ground_truth'] = df_cleaned['clarifying_question']\n",
        "\n",
        "# 필요한 컬럼만 남기기\n",
        "df_final = df_cleaned[['user_query', 'ground_truth']].copy()\n",
        "\n",
        "# NONE 케이스 마스크 (regex=False 추가!)\n",
        "none_mask = df_final['user_query'].str.contains('[NONE|NONE]', regex=False)\n",
        "\n",
        "# ground_truth를 <NO_CLARIFYING_QUESTION>으로 채우기\n",
        "df_final.loc[none_mask, 'ground_truth'] = '<NO_CLARIFYING_QUESTION>'\n",
        "\n",
        "print(f\"✓ DataFrame 생성 완료!\")\n",
        "print(f\"총 데이터 개수: {len(df_final)}\")\n",
        "print(f\"NONE 데이터: {none_mask.sum()}개 ({none_mask.sum()/len(df_final)*100:.1f}%)\")\n",
        "print(f\"모호한 질문: {(~none_mask).sum()}개 ({(~none_mask).sum()/len(df_final)*100:.1f}%)\")"
      ],
      "metadata": {
        "id": "Mv86XQKazHY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 랜덤으로 10개 샘플 확인\n",
        "import random\n",
        "\n",
        "sample_indices = random.sample(range(len(df_final)), 10)\n",
        "\n",
        "for i, idx in enumerate(sample_indices, 1):\n",
        "    row = df_final.iloc[idx]\n",
        "    print(f\"\\n[샘플 {i}] (인덱스: {idx})\")\n",
        "    print(\"-\"*80)\n",
        "    print(f\"User Query: {row['user_query']}\")\n",
        "    print(f\"Ground Truth: {row['ground_truth']}\")"
      ],
      "metadata": {
        "id": "e_umc3PvzJ1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# 모호한 질문과 명확한 질문 분리\n",
        "ambiguous_df = df_final[~none_mask].copy()\n",
        "none_df = df_final[none_mask].copy()\n",
        "\n",
        "print(f\"\\n분리 전:\")\n",
        "print(f\"- 모호한 질문: {len(ambiguous_df)}개\")\n",
        "print(f\"- 명확한 질문 (NONE): {len(none_df)}개\")\n",
        "\n",
        "# NONE 데이터를 5%만 샘플링\n",
        "target_none_count = int(len(ambiguous_df) * 0.05)  # 모호한 질문의 5%\n",
        "none_sampled = none_df.sample(n=min(target_none_count, len(none_df)), random_state=42)\n",
        "\n",
        "# 합치기\n",
        "df_final = pd.concat([ambiguous_df, none_sampled], ignore_index=True)\n",
        "\n",
        "# 섞기\n",
        "df_final = df_final.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "print(f\"\\n샘플링 후:\")\n",
        "print(f\"- 모호한 질문: {len(ambiguous_df)}개\")\n",
        "print(f\"- 명확한 질문 (NONE): {len(none_sampled)}개 ({len(none_sampled)/len(df_final)*100:.1f}%)\")\n",
        "print(f\"- 총 데이터: {len(df_final)}개\")\n",
        "\n",
        "print(\"\\n컬럼 목록:\", df_final.columns.tolist())\n",
        "print(\"\\n결측치 확인:\")\n",
        "print(df_final.isnull().sum())"
      ],
      "metadata": {
        "id": "emLo4YZY06O0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 최종 분포 확인\n",
        "print(\"=\"*80)\n",
        "print(\"최종 데이터 분포:\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "none_final_mask = df_final['user_query'].str.contains('[NONE|NONE]', regex=False)\n",
        "print(f\"NONE: {none_final_mask.sum()}개 ({none_final_mask.sum()/len(df_final)*100:.1f}%)\")\n",
        "print(f\"모호한 질문: {(~none_final_mask).sum()}개 ({(~none_final_mask).sum()/len(df_final)*100:.1f}%)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"NONE 샘플 3개:\")\n",
        "print(\"=\"*80)\n",
        "display(df_final[none_final_mask].head(3))\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"모호한 질문 샘플 3개:\")\n",
        "print(\"=\"*80)\n",
        "display(df_final[~none_final_mask].head(3))"
      ],
      "metadata": {
        "id": "8IStV0mU096V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# 저장 경로\n",
        "save_path = '/content/drive/MyDrive/Colab Notebooks/woke-odds/dpo_base_data.jsonl'\n",
        "\n",
        "# JSONL 저장\n",
        "with open(save_path, 'w', encoding='utf-8') as f:\n",
        "    for idx, row in df_final.iterrows():\n",
        "        json_line = {\n",
        "            'user_query': row['user_query'],\n",
        "            'ground_truth': row['ground_truth']\n",
        "        }\n",
        "        f.write(json.dumps(json_line, ensure_ascii=False) + '\\n')\n",
        "\n",
        "print(f\"✓ JSONL 저장 완료!\")\n",
        "print(f\"저장 경로: {save_path}\")\n",
        "print(f\"저장된 데이터 개수: {len(df_final)}개\")\n",
        "\n",
        "# 저장 확인\n",
        "print(\"\\n저장된 파일 크기 확인:\")\n",
        "import os\n",
        "file_size = os.path.getsize(save_path)\n",
        "print(f\"파일 크기: {file_size / 1024:.2f} KB ({file_size / 1024 / 1024:.2f} MB)\")"
      ],
      "metadata": {
        "id": "5wRBSf4D1Bob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 저장된 파일 다시 불러와서 확인\n",
        "print(\"=\"*80)\n",
        "print(\"저장된 파일 확인:\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "test_data = []\n",
        "with open(save_path, 'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        test_data.append(json.loads(line))\n",
        "\n",
        "print(f\"불러온 데이터 개수: {len(test_data)}\")\n",
        "print(\"\\n첫 3개 샘플:\")\n",
        "for i, sample in enumerate(test_data[:3], 1):\n",
        "    print(f\"\\n[샘플 {i}]\")\n",
        "    print(f\"User Query: {sample['user_query']}\")\n",
        "    print(f\"Ground Truth: {sample['ground_truth']}\")\n",
        "\n",
        "print(\"\\n✓ 파일이 정상적으로 저장되었습니다!\")"
      ],
      "metadata": {
        "id": "EzGeNjdQ1lU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 후보 생성 테스트"
      ],
      "metadata": {
        "id": "HLdvFJR62L2D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def generate_candidates_for_query(user_query, model, tokenizer, num_candidates=5):\n",
        "    \"\"\"\n",
        "    하나의 쿼리에 대해 여러 후보 생성\n",
        "\n",
        "    Returns:\n",
        "        list: 생성된 후보 텍스트 리스트\n",
        "    \"\"\"\n",
        "    # messages 구성\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "        {\"role\": \"user\", \"content\": user_query}\n",
        "    ]\n",
        "\n",
        "    # Chat template 적용\n",
        "    prompt = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True\n",
        "    )\n",
        "\n",
        "    # 토크나이즈\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    candidates = []\n",
        "    temperatures = [0.7, 0.9, 1.1, 1.3, 1.5]\n",
        "\n",
        "    for temp in temperatures[:num_candidates]:\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=150,\n",
        "                temperature=temp,\n",
        "                top_p=0.95,\n",
        "                do_sample=True,\n",
        "                pad_token_id=tokenizer.pad_token_id,\n",
        "                eos_token_id=tokenizer.eos_token_id\n",
        "            )\n",
        "\n",
        "        generated_text = tokenizer.decode(\n",
        "            outputs[0][inputs['input_ids'].shape[1]:],\n",
        "            skip_special_tokens=True\n",
        "        ).strip()\n",
        "\n",
        "        candidates.append(generated_text)\n",
        "\n",
        "    # 중복 제거하되, 5개 유지\n",
        "    unique_candidates = []\n",
        "    seen = set()\n",
        "    for cand in candidates:\n",
        "        if cand not in seen:\n",
        "            unique_candidates.append(cand)\n",
        "            seen.add(cand)\n",
        "\n",
        "    # 5개 미만이면 재생성 (높은 temperature로)\n",
        "    while len(unique_candidates) < num_candidates:\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=150,\n",
        "                temperature=1.5 + len(unique_candidates) * 0.1,  # 점점 높임\n",
        "                top_p=0.95,\n",
        "                do_sample=True,\n",
        "                pad_token_id=tokenizer.pad_token_id,\n",
        "                eos_token_id=tokenizer.eos_token_id\n",
        "            )\n",
        "\n",
        "        generated_text = tokenizer.decode(\n",
        "            outputs[0][inputs['input_ids'].shape[1]:],\n",
        "            skip_special_tokens=True\n",
        "        ).strip()\n",
        "\n",
        "        if generated_text not in seen:\n",
        "            unique_candidates.append(generated_text)\n",
        "            seen.add(generated_text)\n",
        "\n",
        "    return unique_candidates[:num_candidates]\n",
        "\n",
        "print(\"후보 생성 함수 정의 완료!\")"
      ],
      "metadata": {
        "id": "_BiBz5VasVa1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 먼저 3개만 테스트\n",
        "print(\"3개 샘플로 테스트 시작...\\n\")\n",
        "\n",
        "test_df = df_final.head(3).copy()\n",
        "\n",
        "# 후보 컬럼 추가\n",
        "for i in range(5):\n",
        "    test_df[f'candidate_{i+1}'] = None\n",
        "\n",
        "# 생성\n",
        "for idx, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"후보 생성 중\"):\n",
        "    user_query = row['user_query']\n",
        "\n",
        "    try:\n",
        "        candidates = generate_candidates_for_query(user_query, model, tokenizer)\n",
        "\n",
        "        # DataFrame에 저장\n",
        "        for i, cand in enumerate(candidates):\n",
        "            test_df.at[idx, f'candidate_{i+1}'] = cand\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n에러 발생 (idx={idx}): {e}\")\n",
        "        continue\n",
        "\n",
        "print(\"\\n테스트 완료!\")\n",
        "print(\"\\n결과 확인:\")\n",
        "print(test_df[['user_query', 'ground_truth', 'candidate_1', 'candidate_2']].head(3))"
      ],
      "metadata": {
        "id": "h71yacaish7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 한 샘플씩 세로로 보기 (더 깔끔함)\n",
        "def show_sample(df, idx):\n",
        "    \"\"\"\n",
        "    DataFrame의 특정 행을 보기 좋게 출력\n",
        "    \"\"\"\n",
        "    row = df.iloc[idx]\n",
        "    print(\"=\"*80)\n",
        "    print(f\"[샘플 {idx}]\")\n",
        "    print(\"=\"*80)\n",
        "    for col in df.columns:\n",
        "        print(f\"\\n{col}:\")\n",
        "        print(f\"  {row[col]}\")\n",
        "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "\n",
        "# 사용\n",
        "show_sample(test_df, 0)\n",
        "show_sample(test_df, 1)\n",
        "show_sample(test_df, 2)"
      ],
      "metadata": {
        "id": "TJf7gFuMskhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3개 샘플 테스트"
      ],
      "metadata": {
        "id": "fgtHQliJ3Aqa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3개 샘플만 추출\n",
        "df_test = df_final.head(3).copy()\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"테스트용 3개 샘플:\")\n",
        "print(\"=\"*80)\n",
        "display(df_test)\n",
        "\n",
        "# 후보 생성할 컬럼 추가 (5개)\n",
        "for i in range(5):\n",
        "    df_test[f'candidate_{i+1}'] = None\n",
        "\n",
        "print(\"\\n후보 생성 시작...\\n\")\n",
        "\n",
        "# 각 샘플에 대해 5개 후보 생성\n",
        "for idx in range(len(df_test)):\n",
        "    row = df_test.iloc[idx]\n",
        "    user_query = row['user_query']\n",
        "\n",
        "    print(f\"[{idx+1}/3] 생성 중: {user_query[:60]}...\")\n",
        "\n",
        "    # messages 구성\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "        {\"role\": \"user\", \"content\": user_query}\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        candidates = generate_candidates_for_query(user_query, model, tokenizer, num_candidates=5)\n",
        "\n",
        "        # DataFrame에 저장\n",
        "        for i, cand in enumerate(candidates):\n",
        "            df_test.at[idx, f'candidate_{i+1}'] = cand\n",
        "\n",
        "        print(f\"  ✓ 완료!\\n\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  ✗ 에러: {e}\\n\")\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"후보 생성 완료!\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "id": "TJc2_Ej3tbGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pandas 표시 옵션\n",
        "pd.set_option('display.max_colwidth', 80)\n",
        "\n",
        "print(\"\\n생성된 DataFrame 구조:\")\n",
        "print(f\"컬럼: {df_test.columns.tolist()}\")\n",
        "print(f\"Shape: {df_test.shape}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"전체 DataFrame:\")\n",
        "print(\"=\"*80)\n",
        "display(df_test)"
      ],
      "metadata": {
        "id": "LubGyPsE3CNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 샘플을 예쁘게 출력\n",
        "for idx in range(len(df_test)):\n",
        "    row = df_test.iloc[idx]\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\"[샘플 {idx+1}]\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"User Query:\\n  {row['user_query']}\\n\")\n",
        "    print(f\"Ground Truth:\\n  {row['ground_truth']}\\n\")\n",
        "    print(f\"생성된 후보 5개:\")\n",
        "    print(\"-\"*80)\n",
        "\n",
        "    for i in range(5):\n",
        "        cand = row[f'candidate_{i+1}']\n",
        "        print(f\"\\n[후보 {i+1}]\")\n",
        "        print(f\"  {cand}\")\n",
        "\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "FsyOTHkV3ETc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 df 삭제\n",
        "del df_test\n",
        "print(\"✓ 테스트 DataFrame 삭제 완료\\n\")"
      ],
      "metadata": {
        "id": "H079KyE33krU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 전체 데이터 작업"
      ],
      "metadata": {
        "id": "plbGq_bN328Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체 데이터로 작업\n",
        "df_with_candidates = df_final.copy()\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(f\"전체 데이터 후보 생성 시작\")\n",
        "print(\"=\"*80)\n",
        "print(f\"총 데이터 개수: {len(df_with_candidates)}개\")\n",
        "print(f\"예상 소요 시간: 약 2-3시간\\n\")\n",
        "\n",
        "# 후보 생성할 컬럼 추가 (5개)\n",
        "for i in range(5):\n",
        "    df_with_candidates[f'candidate_{i+1}'] = None\n",
        "\n",
        "# 배치 처리 (100개씩 중간 저장)\n",
        "batch_size = 100\n",
        "total_batches = (len(df_with_candidates) + batch_size - 1) // batch_size\n",
        "\n",
        "for batch_idx in range(total_batches):\n",
        "    start_idx = batch_idx * batch_size\n",
        "    end_idx = min((batch_idx + 1) * batch_size, len(df_with_candidates))\n",
        "\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"[Batch {batch_idx+1}/{total_batches}] Processing {start_idx}-{end_idx}\")\n",
        "    print('='*80)\n",
        "\n",
        "    for idx in tqdm(range(start_idx, end_idx), desc=f\"Batch {batch_idx+1}\"):\n",
        "        row = df_with_candidates.iloc[idx]\n",
        "        user_query = row['user_query']\n",
        "\n",
        "        try:\n",
        "            candidates = generate_candidates_for_query(user_query, model, tokenizer, num_candidates=5)\n",
        "\n",
        "            # DataFrame에 저장\n",
        "            for i, cand in enumerate(candidates):\n",
        "                df_with_candidates.at[df_with_candidates.index[idx], f'candidate_{i+1}'] = cand\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\n에러 발생 (idx={idx}): {e}\")\n",
        "            continue\n",
        "\n",
        "    # 중간 저장 (100개마다)\n",
        "    temp_save_path = f'/content/drive/MyDrive/Colab Notebooks/woke-odds/candidates_batch_{batch_idx+1}.csv'\n",
        "    df_with_candidates.iloc[:end_idx].to_csv(temp_save_path, index=False, encoding='utf-8-sig')\n",
        "    print(f\"\\n✓ 중간 저장 완료: {temp_save_path}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"✓ 전체 후보 생성 완료!\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "id": "T6sfWCdQ3Gwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 최종 CSV 저장\n",
        "final_save_path = '/content/drive/MyDrive/Colab Notebooks/woke-odds/dpo_with_candidates_full.csv'\n",
        "df_with_candidates.to_csv(final_save_path, index=False, encoding='utf-8-sig')\n",
        "\n",
        "print(f\"✓ 최종 CSV 저장 완료!\")\n",
        "print(f\"저장 경로: {final_save_path}\")\n",
        "print(f\"저장된 데이터 개수: {len(df_with_candidates)}개\")\n",
        "\n",
        "# 통계\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"생성 통계:\")\n",
        "print(\"=\"*80)\n",
        "for i in range(5):\n",
        "    col = f'candidate_{i+1}'\n",
        "    valid_count = df_with_candidates[col].notna().sum()\n",
        "    print(f\"{col}: {valid_count}/{len(df_with_candidates)} ({valid_count/len(df_with_candidates)*100:.1f}%)\")"
      ],
      "metadata": {
        "id": "1lfjaIeu3xdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 랜덤 샘플 3개 확인\n",
        "import random\n",
        "\n",
        "sample_indices = random.sample(range(len(df_with_candidates)), 3)\n",
        "\n",
        "for idx in sample_indices:\n",
        "    row = df_with_candidates.iloc[idx]\n",
        "    print(\"=\"*80)\n",
        "    print(f\"[샘플 {idx}]\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"User Query: {row['user_query']}\")\n",
        "    print(f\"\\nGround Truth: {row['ground_truth']}\")\n",
        "    print(f\"\\n생성된 후보들:\")\n",
        "    for i in range(5):\n",
        "        print(f\"  {i+1}. {row[f'candidate_{i+1}']}\")\n",
        "    print()\n",
        "\n",
        "print(f\"\\n✓ 전체 작업 완료! 총 {len(df_with_candidates)}개 데이터 처리됨\")"
      ],
      "metadata": {
        "id": "fNJaf5gW3zLz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}